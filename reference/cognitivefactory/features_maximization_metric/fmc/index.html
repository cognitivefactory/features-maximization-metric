
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Implementation of Features Maximization Metric, an unbiased metric aimed at estimate the quality of an unsupervised classification.">
      
      
      
        <link rel="canonical" href="https://cognitivefactory.github.io/features-maximization-metric/reference/cognitivefactory/features_maximization_metric/fmc/">
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../../../../contributing/">
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.12">
    
    
      
        <title>fmc - Features Maximization Metric</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.0d440cfe.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.2505c338.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/_markdown_exec_ansi.css">
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../../css/material.css">
    
      <link rel="stylesheet" href="../../../../css/mkdocstrings.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#cognitivefactory.features_maximization_metric.fmc" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Features Maximization Metric" class="md-header__button md-logo" aria-label="Features Maximization Metric" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Features Maximization Metric
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              fmc
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
            </label>
          
        
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/cognitivefactory/features-maximization-metric" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    cognitivefactory/features-maximization-metric
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        Home
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../" class="md-tabs__link md-tabs__link--active">
        Code Reference
      </a>
    </li>
  

  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../contributing/" class="md-tabs__link">
        Development
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Features Maximization Metric" class="md-nav__button md-logo" aria-label="Features Maximization Metric" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Features Maximization Metric
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/cognitivefactory/features-maximization-metric" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    cognitivefactory/features-maximization-metric
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
      
      
      
        <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
          Home
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          Home
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../usage/" class="md-nav__link">
        Usage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../changelog/" class="md-nav__link">
        Changelog
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../credits/" class="md-nav__link">
        Credits
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../license/" class="md-nav__link">
        License
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
      
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          Code Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Code Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" checked>
      
      
      
        <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
          cognitivefactory
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          cognitivefactory
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_1" checked>
      
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../">features_maximization_metric</a>
          
            <label for="__nav_2_1_1">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_1_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_2_1_1">
          <span class="md-nav__icon md-icon"></span>
          features_maximization_metric
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          fmc
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        fmc
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#cognitivefactory.features_maximization_metric.fmc" class="md-nav__link">
    cognitivefactory.features_maximization_metric.fmc
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric" class="md-nav__link">
    FeaturesMaximizationMetric
  </a>
  
    <nav class="md-nav" aria-label="FeaturesMaximizationMetric">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.compare" class="md-nav__link">
    compare()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.get_most_activated_classes_by_a_feature" class="md-nav__link">
    get_most_activated_classes_by_a_feature()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.get_most_active_features_by_a_classe" class="md-nav__link">
    get_most_active_features_by_a_classe()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
      
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          Development
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Development
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../contributing/" class="md-nav__link">
        Contributing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../code_of_conduct/" class="md-nav__link">
        Code of Conduct
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../coverage/" class="md-nav__link">
        Coverage report
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#cognitivefactory.features_maximization_metric.fmc" class="md-nav__link">
    cognitivefactory.features_maximization_metric.fmc
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric" class="md-nav__link">
    FeaturesMaximizationMetric
  </a>
  
    <nav class="md-nav" aria-label="FeaturesMaximizationMetric">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.compare" class="md-nav__link">
    compare()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.get_most_activated_classes_by_a_feature" class="md-nav__link">
    get_most_activated_classes_by_a_feature()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.get_most_active_features_by_a_classe" class="md-nav__link">
    get_most_active_features_by_a_classe()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  



  <h1>fmc</h1>

<div class="doc doc-object doc-module">


<a id="cognitivefactory.features_maximization_metric.fmc"></a>
  <div class="doc doc-contents first">
  
      <ul>
<li>Name:         cognitivefactory.features_maximization_metric.fmc</li>
<li>Description:  Implementation of Features Maximization Metrics.</li>
<li>Author:       Erwan SCHILD</li>
<li>Created:      23/11/2022</li>
<li>Licence:      CeCILL-C License v1.0 (<a href="https://cecill.info/licences.fr.html">https://cecill.info/licences.fr.html</a>)</li>
</ul>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric" class="doc doc-heading">
        <code>FeaturesMaximizationMetric</code>


<a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">

  
      <p>This class implements the <strong><em>Features Maximization Metric</em></strong>.
It's a dataset modelization based on vectors features and data labels:
for each couple <code>(feature, classe)</code>, it gives a score (called <strong>F-Measure</strong>) that describe the power of identification and distinction of the feature for this classe.</p>

<details class="this-metric-is-computed-by-applying-the-following-steps">
  <summary>This metric is computed by applying the following steps</summary>
  <ol>
<li>
<p>Compute the <strong><em>Features F-Measure</em></strong> metric (based on <strong><em>Features Recall</em></strong> and <strong><em>Features Predominance</em></strong> metrics).</p>
<blockquote>
<p>(a) The <strong><em>Features Recall</em></strong> <code>FR[f][c]</code> for a given class <code>c</code> and a given feature <code>f</code> is the ratio between
the sum of the vectors weights of the feature <code>f</code> for data in class <code>c</code>
and the sum of all vectors weights of feature <code>f</code> for all data.
It answers the question: "<em>Can the feature <code>f</code> distinguish the class <code>c</code> from other classes <code>c'</code> ?</em>"</p>
<p>(b) The <strong><em>Features Predominance</em></strong> <code>FP[f][c]</code> for a given class <code>c</code> and a given feature <code>f</code> is the ratio between
the sum of the vectors weights of the feature <code>f</code> for data in class <code>c</code>
and the sum of all vectors weights of all feature <code>f'</code> for data in class <code>c</code>.
It answers the question: "<em>Can the feature <code>f</code> better identify the class <code>c</code> than the other features <code>f'</code> ?</em>"</p>
<p>(c) The <strong><em>Features F-Measure</em></strong> <code>FM[f][c]</code> for a given class <code>c</code> and a given feature <code>f</code> is
the harmonic mean of the <strong><em>Features Recall</em></strong> (a) and the <strong><em>Features Predominance</em></strong> (c).
It answers the question: "<em>How much information does the feature <code>f</code> contain about the class <code>c</code> ?</em>"</p>
</blockquote>
</li>
<li>
<p>Compute the <strong><em>Features Selection</em></strong> (based on <strong><em>F-Measure Overall Average</em></strong> comparison).</p>
<blockquote>
<p>(d) The <strong><em>F-Measure Overall Average</em></strong> is the average of <strong><em>Features F-Measure</em></strong> (c) for all classes <code>c</code> and for all features <code>f</code>.
It answers the question: "<em>What are the mean of information contained by features in all classes ?</em>"</p>
<p>(e) A feature <code>f</code> is <strong><em>Selected</em></strong> if and only if it exist at least one class <code>c</code> for which the <strong><em>Features F-Measure</em></strong> (c) <code>FM[f][c]</code> is bigger than the <strong><em>F-Measure Overall Average</em></strong> (d).
It answers the question: "<em>What are the features which contain more information than the mean of information in the dataset ?</em>"</p>
<p>(f) A Feature <code>f</code> is <strong><em>Deleted</em></strong> if and only if the <strong><em>Features F-Measure</em></strong> (c) <code>FM[f][c]</code> is always lower than the <strong><em>F-Measure Overall Average</em></strong> (d) for each class <code>c</code>.
It answers the question: "<em>What are the features which do not contain more information than the mean of information in the dataset ?</em>"</p>
</blockquote>
</li>
<li>
<p>Compute the <strong><em>Features Contrast</em></strong> and <strong><em>Features Activation</em></strong> (based on <strong><em>F-Measure Marginal Averages</em></strong> comparison).</p>
<blockquote>
<p>(g) The <strong><em>F-Measure Marginal Averages</em></strong> for a given feature <code>f</code> is the average of <strong><em>Features F-Measure</em></strong> (c) for all classes <code>c</code> and for the given feature <code>f</code>.
It answers the question: "<em>What are the mean of information contained by the feature <code>f</code> in all classes ?</em>"</p>
<p>(h) The <strong><em>Features Contrast</em></strong> <code>FC[f][c]</code> for a given class <code>c</code> and a given selected feature <code>f</code> is the ratio between
the <strong><em>Features F-Measure</em></strong> (c) <code>FM[f][c]</code>
and the <strong><em>F-Measure Marginal Averages</em></strong> (g) for selected feature f
put to the power of an <strong><em>Amplification Factor</em></strong>.
It answers the question: "<em>How relevant is the feature <code>f</code> to distinguish the class <code>c</code> ?</em>"</p>
<p>(i) A selected Feature <code>f</code> is <strong><em>Active</em></strong> for a given class <code>c</code> if and only if the <strong><em>Features Contrast</em></strong> (h) <code>FC[f][c]</code> is bigger than <code>1.0</code>.
It answers the question : "<em>For which classes a selected feature <code>f</code> is relevant ?</em>"</p>
</blockquote>
</li>
</ol>
</details>      <p>In order to <strong><em>evaluate it according to a reference</em></strong>, a FMC modelization is represented by the Features Activation of its vector features,
and a similarity score to the reference is computed, based on common metrics on clustering (homogeneity, completeness, v_measure).</p>

  <p><strong>Attributes:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>data_vectors</code></td>
          <td>
                <code><span title="scipy.sparse.csr_matrix">csr_matrix</span></code>
          </td>
          <td><p>The sparse matrix representing the vector of each data (i.e. <code>data_vectors[d,f]</code> is the weight of data <code>d</code> for feature <code>f</code>).</p></td>
        </tr>
        <tr>
          <td><code>data_classes</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>The list representing the class of each data (i.e. <code>data_classes[d]</code> is the class of data <code>d</code>).</p></td>
        </tr>
        <tr>
          <td><code>list_of_possible_features</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>The list of existing vectors features.</p></td>
        </tr>
        <tr>
          <td><code>list_of_possible_classes</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>The list of existing data classes.</p></td>
        </tr>
        <tr>
          <td><code>amplification_factor</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>The positive integer called "amplification factor" aimed at emphasize the feature contrast. Usually at <code>1</code>.</p></td>
        </tr>
        <tr>
          <td><code>features_frecall</code></td>
          <td>
                <code><span title="typing.Dict">Dict</span>[str, <span title="typing.Dict">Dict</span>[str, float]]</code>
          </td>
          <td><p>The computation of <em>Features Recall</em> (<em>Can the feature <code>f</code> distinguish the class <code>c</code> from other classes <code>l'</code> ?</em>).</p></td>
        </tr>
        <tr>
          <td><code>features_fpredominance</code></td>
          <td>
                <code><span title="typing.Dict">Dict</span>[str, <span title="typing.Dict">Dict</span>[str, float]]</code>
          </td>
          <td><p>The computation of <em>Features Predominance</em> (<em>Can the feature <code>f</code> better identify the class <code>c</code> than the other features <code>f'</code> ?</em>).</p></td>
        </tr>
        <tr>
          <td><code>features_fmeasure</code></td>
          <td>
                <code><span title="typing.Dict">Dict</span>[str, <span title="typing.Dict">Dict</span>[str, float]]</code>
          </td>
          <td><p>The computation of <em>Features F-Measure</em> (<em>How much information does the feature <code>f</code> contain about the class <code>c</code> ?</em>).</p></td>
        </tr>
        <tr>
          <td><code>features_overall_average</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>The computation of <em>Overall Average of Features F-Measure</em> (<em>What are the mean of information contained by features in all classes ?</em>).</p></td>
        </tr>
        <tr>
          <td><code>features_selection</code></td>
          <td>
                <code><span title="typing.Dict">Dict</span>[str, bool]</code>
          </td>
          <td><p>The computation of <em>Features Selected</em> (<em>What are the features which contain more information than the mean of information in the dataset ?</em>).</p></td>
        </tr>
        <tr>
          <td><code>features_marginal_averages</code></td>
          <td>
                <code><span title="typing.Dict">Dict</span>[str, float]</code>
          </td>
          <td><p>The computation of <em>Marginal Averages of Features F-Measure</em> (<em>What are the mean of information contained by the feature <code>f</code> in all classes ?</em>).</p></td>
        </tr>
        <tr>
          <td><code>features_contrast</code></td>
          <td>
                <code><span title="typing.Dict">Dict</span>[str, <span title="typing.Dict">Dict</span>[str, float]]</code>
          </td>
          <td><p>The computation of <em>Features Contrast</em> (<em>How important is the feature <code>f</code> to distinguish the class <code>c</code> ?</em>).</p></td>
        </tr>
        <tr>
          <td><code>features_activation</code></td>
          <td>
                <code><span title="typing.Dict">Dict</span>[str, <span title="typing.Dict">Dict</span>[str, bool]]</code>
          </td>
          <td><p>The computation of <em>Features Activation</em> (<em>For which classes a selected feature <code>f</code> is relevant ?</em>).</p></td>
        </tr>
    </tbody>
  </table>

<details class="example">
  <summary>Example</summary>
  <ul>
<li>Basic usecase: "<em>What are the physical characteristics that most distinguish men from women ?</em>"
<div class="highlight"><pre><span></span><code><span class="c1"># Problem to solve.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&gt;&gt; What are the physical characteristics that most distinguish men from women ?&quot;</span><span class="p">)</span>

<span class="c1">###</span>
<span class="c1">### Python dependencies.</span>
<span class="c1">###</span>

<span class="kn">from</span> <span class="nn">cognitivefactory.features_maximization_metric.fmc</span> <span class="kn">import</span> <span class="n">FeaturesMaximizationMetric</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>

<span class="c1">###</span>
<span class="c1">### Data.</span>
<span class="c1">###</span>

<span class="c1"># Define people characteristics that will be studied.</span>
<span class="n">characteristics_studied</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Shoes size&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Hair size&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Nose size&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="c1"># Get people characteristics.</span>
<span class="n">people_characteristics</span><span class="p">:</span> <span class="n">csr_matrix</span> <span class="o">=</span> <span class="n">csr_matrix</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Get people genders.</span>
<span class="n">people_genders</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Man&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Man&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Man&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Woman&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Woman&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Woman&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="c1">###</span>
<span class="c1">### Feature Maximization Metrics.</span>
<span class="c1">###</span>

<span class="c1"># Main computation.</span>
<span class="n">fmc_computer</span><span class="p">:</span> <span class="n">FeaturesMaximizationMetric</span> <span class="o">=</span> <span class="n">FeaturesMaximizationMetric</span><span class="p">(</span>
    <span class="n">data_vectors</span><span class="o">=</span><span class="n">people_characteristics</span><span class="p">,</span>
    <span class="n">data_classes</span><span class="o">=</span><span class="n">people_genders</span><span class="p">,</span>
    <span class="n">list_of_possible_features</span><span class="o">=</span><span class="n">characteristics_studied</span><span class="p">,</span>
    <span class="n">amplification_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1">###</span>
<span class="c1">### Analysis 1: Delete characteristics that aren&#39;t relevant.</span>
<span class="c1">###</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="s2">&quot;1. Which characteristic seems not relevant to distinguish men from women ?&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">for</span> <span class="n">characteristic</span> <span class="ow">in</span> <span class="n">characteristics_studied</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">fmc_computer</span><span class="o">.</span><span class="n">features_selection</span><span class="p">[</span><span class="n">characteristic</span><span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;    - &#39;</span><span class="si">{0}</span><span class="s2">&#39; seems not relevant.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">characteristic</span><span class="p">)</span>
        <span class="p">)</span>

<span class="c1">###</span>
<span class="c1">### Analysis 2: Describe gender by relevant characteristics.</span>
<span class="c1">###</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="s2">&quot;2. According to remaining characteristics:&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">for</span> <span class="n">gender</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">people_genders</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;    - Which characteristic seems important to recognize a &#39;</span><span class="si">{0}</span><span class="s2">&#39; ?&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gender</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">characteristic</span> <span class="ow">in</span> <span class="n">fmc_computer</span><span class="o">.</span><span class="n">get_most_active_features_by_a_classe</span><span class="p">(</span>
        <span class="n">classe</span><span class="o">=</span><span class="n">gender</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;        - &#39;</span><span class="si">{0}</span><span class="s2">&#39; seems important (fmeasure of &#39;</span><span class="si">{1:.2f}</span><span class="s2">&#39;, contrast of &#39;</span><span class="si">{2:.2f}</span><span class="s2">&#39;).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">characteristic</span><span class="p">,</span>
                <span class="n">fmc_computer</span><span class="o">.</span><span class="n">features_fmeasure</span><span class="p">[</span><span class="n">characteristic</span><span class="p">][</span><span class="n">gender</span><span class="p">],</span>
                <span class="n">fmc_computer</span><span class="o">.</span><span class="n">features_contrast</span><span class="p">[</span><span class="n">characteristic</span><span class="p">][</span><span class="n">gender</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="p">)</span>
</code></pre></div></li>
</ul>
</details>
<details class="references">
  <summary>References</summary>
  <ul>
<li>Features Maximization Metric: <code>Lamirel J.-C., Cuxac P., Hajlaoui K., A new approach for feature selection based on quality metric, Advances in Knowledge Discovery and Management, 6 (665), Springer.</code></li>
</ul>
</details>

        <details class="quote">
          <summary>Source code in <code>cognitivefactory\features_maximization_metric\fmc.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">FeaturesMaximizationMetric</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This class implements the ***Features Maximization Metric***.</span>
<span class="sd">    It&#39;s a dataset modelization based on vectors features and data labels:</span>
<span class="sd">    for each couple `(feature, classe)`, it gives a score (called **F-Measure**) that describe the power of identification and distinction of the feature for this classe.</span>

<span class="sd">    This metric is computed by applying the following steps:</span>

<span class="sd">        1. Compute the ***Features F-Measure*** metric (based on ***Features Recall*** and ***Features Predominance*** metrics).</span>

<span class="sd">            &gt; (a) The ***Features Recall*** `FR[f][c]` for a given class `c` and a given feature `f` is the ratio between</span>
<span class="sd">            &gt; the sum of the vectors weights of the feature `f` for data in class `c`</span>
<span class="sd">            &gt; and the sum of all vectors weights of feature `f` for all data.</span>
<span class="sd">            &gt; It answers the question: &quot;_Can the feature `f` distinguish the class `c` from other classes `c&#39;` ?_&quot;</span>

<span class="sd">            &gt; (b) The ***Features Predominance*** `FP[f][c]` for a given class `c` and a given feature `f` is the ratio between</span>
<span class="sd">            &gt; the sum of the vectors weights of the feature `f` for data in class `c`</span>
<span class="sd">            &gt; and the sum of all vectors weights of all feature `f&#39;` for data in class `c`.</span>
<span class="sd">            &gt; It answers the question: &quot;_Can the feature `f` better identify the class `c` than the other features `f&#39;` ?_&quot;</span>

<span class="sd">            &gt; (c) The ***Features F-Measure*** `FM[f][c]` for a given class `c` and a given feature `f` is</span>
<span class="sd">            &gt; the harmonic mean of the ***Features Recall*** (a) and the ***Features Predominance*** (c).</span>
<span class="sd">            &gt; It answers the question: &quot;_How much information does the feature `f` contain about the class `c` ?_&quot;</span>

<span class="sd">        2. Compute the ***Features Selection*** (based on ***F-Measure Overall Average*** comparison).</span>

<span class="sd">            &gt; (d) The ***F-Measure Overall Average*** is the average of ***Features F-Measure*** (c) for all classes `c` and for all features `f`.</span>
<span class="sd">            &gt; It answers the question: &quot;_What are the mean of information contained by features in all classes ?_&quot;</span>

<span class="sd">            &gt; (e) A feature `f` is ***Selected*** if and only if it exist at least one class `c` for which the ***Features F-Measure*** (c) `FM[f][c]` is bigger than the ***F-Measure Overall Average*** (d).</span>
<span class="sd">            &gt; It answers the question: &quot;_What are the features which contain more information than the mean of information in the dataset ?_&quot;</span>

<span class="sd">            &gt; (f) A Feature `f` is ***Deleted*** if and only if the ***Features F-Measure*** (c) `FM[f][c]` is always lower than the ***F-Measure Overall Average*** (d) for each class `c`.</span>
<span class="sd">            &gt; It answers the question: &quot;_What are the features which do not contain more information than the mean of information in the dataset ?_&quot;</span>

<span class="sd">        3. Compute the ***Features Contrast*** and ***Features Activation*** (based on ***F-Measure Marginal Averages*** comparison).</span>

<span class="sd">            &gt; (g) The ***F-Measure Marginal Averages*** for a given feature `f` is the average of ***Features F-Measure*** (c) for all classes `c` and for the given feature `f`.</span>
<span class="sd">            &gt; It answers the question: &quot;_What are the mean of information contained by the feature `f` in all classes ?_&quot;</span>

<span class="sd">            &gt; (h) The ***Features Contrast*** `FC[f][c]` for a given class `c` and a given selected feature `f` is the ratio between</span>
<span class="sd">            &gt; the ***Features F-Measure*** (c) `FM[f][c]`</span>
<span class="sd">            &gt; and the ***F-Measure Marginal Averages*** (g) for selected feature f</span>
<span class="sd">            &gt; put to the power of an ***Amplification Factor***.</span>
<span class="sd">            &gt; It answers the question: &quot;_How relevant is the feature `f` to distinguish the class `c` ?_&quot;</span>

<span class="sd">            &gt; (i) A selected Feature `f` is ***Active*** for a given class `c` if and only if the ***Features Contrast*** (h) `FC[f][c]` is bigger than `1.0`.</span>
<span class="sd">            &gt; It answers the question : &quot;_For which classes a selected feature `f` is relevant ?_&quot;</span>

<span class="sd">    In order to ***evaluate it according to a reference***, a FMC modelization is represented by the Features Activation of its vector features,</span>
<span class="sd">    and a similarity score to the reference is computed, based on common metrics on clustering (homogeneity, completeness, v_measure).</span>

<span class="sd">    Attributes:</span>
<span class="sd">        data_vectors (csr_matrix): The sparse matrix representing the vector of each data (i.e. `data_vectors[d,f]` is the weight of data `d` for feature `f`).</span>
<span class="sd">        data_classes (List[str]): The list representing the class of each data (i.e. `data_classes[d]` is the class of data `d`).</span>
<span class="sd">        list_of_possible_features (List[str]): The list of existing vectors features.</span>
<span class="sd">        list_of_possible_classes (List[str]):  The list of existing data classes.</span>
<span class="sd">        amplification_factor (int): The positive integer called &quot;amplification factor&quot; aimed at emphasize the feature contrast. Usually at `1`.</span>
<span class="sd">        features_frecall (Dict[str, Dict[str, float]]): The computation of *Features Recall* (_Can the feature `f` distinguish the class `c` from other classes `l&#39;` ?_).</span>
<span class="sd">        features_fpredominance (Dict[str, Dict[str, float]]): The computation of *Features Predominance* (_Can the feature `f` better identify the class `c` than the other features `f&#39;` ?_).</span>
<span class="sd">        features_fmeasure (Dict[str, Dict[str, float]]): The computation of *Features F-Measure* (_How much information does the feature `f` contain about the class `c` ?_).</span>
<span class="sd">        features_overall_average (float): The computation of *Overall Average of Features F-Measure* (_What are the mean of information contained by features in all classes ?_).</span>
<span class="sd">        features_selection (Dict[str, bool]): The computation of *Features Selected* (_What are the features which contain more information than the mean of information in the dataset ?_).</span>
<span class="sd">        features_marginal_averages (Dict[str, float]):  The computation of *Marginal Averages of Features F-Measure* (_What are the mean of information contained by the feature `f` in all classes ?_).</span>
<span class="sd">        features_contrast (Dict[str, Dict[str, float]]): The computation of *Features Contrast* (_How important is the feature `f` to distinguish the class `c` ?_).</span>
<span class="sd">        features_activation (Dict[str, Dict[str, bool]]): The computation of *Features Activation* (_For which classes a selected feature `f` is relevant ?_).</span>

<span class="sd">    Example:</span>
<span class="sd">        - Basic usecase: &quot;_What are the physical characteristics that most distinguish men from women ?_&quot;</span>
<span class="sd">        ```python</span>

<span class="sd">        # Problem to solve.</span>
<span class="sd">        print(&quot;&gt;&gt; What are the physical characteristics that most distinguish men from women ?&quot;)</span>

<span class="sd">        ###</span>
<span class="sd">        ### Python dependencies.</span>
<span class="sd">        ###</span>

<span class="sd">        from cognitivefactory.features_maximization_metric.fmc import FeaturesMaximizationMetric</span>
<span class="sd">        from scipy.sparse import csr_matrix</span>
<span class="sd">        from typing import List</span>

<span class="sd">        ###</span>
<span class="sd">        ### Data.</span>
<span class="sd">        ###</span>

<span class="sd">        # Define people characteristics that will be studied.</span>
<span class="sd">        characteristics_studied: List[str] = [</span>
<span class="sd">            &quot;Shoes size&quot;,</span>
<span class="sd">            &quot;Hair size&quot;,</span>
<span class="sd">            &quot;Nose size&quot;,</span>
<span class="sd">        ]</span>

<span class="sd">        # Get people characteristics.</span>
<span class="sd">        people_characteristics: csr_matrix = csr_matrix(</span>
<span class="sd">            [</span>
<span class="sd">                [9, 5, 5],</span>
<span class="sd">                [9, 10, 5],</span>
<span class="sd">                [9, 20, 6],</span>
<span class="sd">                [5, 15, 5],</span>
<span class="sd">                [6, 25, 6],</span>
<span class="sd">                [5, 25, 5],</span>
<span class="sd">            ]</span>
<span class="sd">        )</span>

<span class="sd">        # Get people genders.</span>
<span class="sd">        people_genders: List[str] = [</span>
<span class="sd">            &quot;Man&quot;,</span>
<span class="sd">            &quot;Man&quot;,</span>
<span class="sd">            &quot;Man&quot;,</span>
<span class="sd">            &quot;Woman&quot;,</span>
<span class="sd">            &quot;Woman&quot;,</span>
<span class="sd">            &quot;Woman&quot;,</span>
<span class="sd">        ]</span>

<span class="sd">        ###</span>
<span class="sd">        ### Feature Maximization Metrics.</span>
<span class="sd">        ###</span>

<span class="sd">        # Main computation.</span>
<span class="sd">        fmc_computer: FeaturesMaximizationMetric = FeaturesMaximizationMetric(</span>
<span class="sd">            data_vectors=people_characteristics,</span>
<span class="sd">            data_classes=people_genders,</span>
<span class="sd">            list_of_possible_features=characteristics_studied,</span>
<span class="sd">            amplification_factor=1,</span>
<span class="sd">        )</span>

<span class="sd">        ###</span>
<span class="sd">        ### Analysis 1: Delete characteristics that aren&#39;t relevant.</span>
<span class="sd">        ###</span>

<span class="sd">        print(</span>
<span class="sd">            &quot;\n&quot;,</span>
<span class="sd">            &quot;1. Which characteristic seems not relevant to distinguish men from women ?&quot;,</span>
<span class="sd">        )</span>
<span class="sd">        for characteristic in characteristics_studied:</span>
<span class="sd">            if not fmc_computer.features_selection[characteristic]:</span>
<span class="sd">                print(</span>
<span class="sd">                    &quot;    - &#39;{0}&#39; seems not relevant.&quot;.format(characteristic)</span>
<span class="sd">                )</span>

<span class="sd">        ###</span>
<span class="sd">        ### Analysis 2: Describe gender by relevant characteristics.</span>
<span class="sd">        ###</span>

<span class="sd">        print(</span>
<span class="sd">            &quot;\n&quot;,</span>
<span class="sd">            &quot;2. According to remaining characteristics:&quot;,</span>
<span class="sd">        )</span>
<span class="sd">        for gender in sorted(set(people_genders)):</span>
<span class="sd">            print(</span>
<span class="sd">                &quot;    - Which characteristic seems important to recognize a &#39;{0}&#39; ?&quot;.format(gender)</span>
<span class="sd">            )</span>

<span class="sd">            for characteristic in fmc_computer.get_most_active_features_by_a_classe(</span>
<span class="sd">                classe=gender,</span>
<span class="sd">            ):</span>
<span class="sd">                print(</span>
<span class="sd">                    &quot;        - &#39;{0}&#39; seems important (fmeasure of &#39;{1:.2f}&#39;, contrast of &#39;{2:.2f}&#39;).&quot;.format(</span>
<span class="sd">                        characteristic,</span>
<span class="sd">                        fmc_computer.features_fmeasure[characteristic][gender],</span>
<span class="sd">                        fmc_computer.features_contrast[characteristic][gender],</span>
<span class="sd">                    )</span>
<span class="sd">                )</span>
<span class="sd">        ```</span>

<span class="sd">    References:</span>
<span class="sd">        - Features Maximization Metric: `Lamirel J.-C., Cuxac P., Hajlaoui K., A new approach for feature selection based on quality metric, Advances in Knowledge Discovery and Management, 6 (665), Springer.`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># =========================================================================================</span>
    <span class="c1"># INITIALIZATION</span>
    <span class="c1"># =========================================================================================</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data_vectors</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
        <span class="n">data_classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">list_of_possible_features</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">amplification_factor</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The constructor for `FeaturesMaximizationMetric` class.</span>
<span class="sd">        It applies the several steps of ***Feature Maximization***:</span>
<span class="sd">            1. Compute the ***Features F-Measure*** metric (based on ***Features Recall*** and ***Features Predominance*** metrics).</span>
<span class="sd">            2. Compute the ***Features Selection*** (based on ***F-Measure Overall Average*** comparison).</span>
<span class="sd">            3. Compute the ***Features Contrast*** and ***Features Activation*** (based on ***F-Measure Marginal Averages*** comparison).</span>

<span class="sd">        Args:</span>
<span class="sd">            data_vectors (scipy.sparse.csr_matrix): A sparse matrix representing the vector of each data (i.e. `data_vectors[d,f]` is the weight of data `d` for feature `f`).</span>
<span class="sd">            data_classes (List[str]): A list representing the class of each data (i.e. `data_classes[d]` is the class of data `d`).</span>
<span class="sd">            list_of_possible_features (List[str]): A list of existing vectors features.</span>
<span class="sd">            amplification_factor (int, optional): A positive integer called &quot;amplification factor&quot; aimed at emphasize the feature contrast. Defaults to `1`.</span>
<span class="sd">            verbose (bool): An option to display progress status of computations. Defaults to `False`.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if `data_vectors` and `data_classes` have inconsistent shapes.</span>
<span class="sd">            ValueError: if `data_vectors` and `list_of_possible_features` have inconsistent shapes.</span>
<span class="sd">            ValueError: if `amplification_factor` is not a positive integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">###</span>
        <span class="c1">### Check parameters.</span>
        <span class="c1">###</span>

        <span class="c1"># Display progress status if requested.</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;`FeaturesMaximizationMetric.__init__`&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;Check parameters.&quot;</span><span class="p">)</span>

        <span class="c1"># Check data size.</span>
        <span class="k">if</span> <span class="n">data_vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_classes</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The vectors `data_vectors` and the list of classes `data_classes` have inconsistent shapes (currently: &#39;</span><span class="si">{0}</span><span class="s2">&#39; vs &#39;</span><span class="si">{1}</span><span class="s2">&#39;).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">data_vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">data_classes</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># Check features size.</span>
        <span class="k">if</span> <span class="n">data_vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_possible_features</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The vectors `data_vectors` and the list of features `list_of_possible_features` have inconsistent shapes (currently: &#39;</span><span class="si">{0}</span><span class="s2">&#39; vs &#39;</span><span class="si">{1}</span><span class="s2">&#39;).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">data_vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">list_of_possible_features</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># Check amplification factor.</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">amplification_factor</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span> <span class="ow">or</span> <span class="n">amplification_factor</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The amplification factor `amplification_factor` has to be a positive integer (currently: &#39;</span><span class="si">{0}</span><span class="s2">&#39;).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">amplification_factor</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1">###</span>
        <span class="c1">### Store parameters.</span>
        <span class="c1">###</span>

        <span class="c1"># Display progress status if requested.</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;`FeaturesMaximizationMetric.__init__`&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;Store parameters.&quot;</span><span class="p">)</span>

        <span class="c1"># Store data information.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_vectors</span><span class="p">:</span> <span class="n">csr_matrix</span> <span class="o">=</span> <span class="n">data_vectors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_classes</span>
        <span class="c1"># Store features and classes lists.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">list_of_possible_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">data_classes</span><span class="p">))</span>
        <span class="c1"># Store amplification factor.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">amplification_factor</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">amplification_factor</span>

        <span class="c1">###</span>
        <span class="c1">### Compute Features Maximization Metric.</span>
        <span class="c1">###</span>

        <span class="c1"># Display progress status if requested.</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;`FeaturesMaximizationMetric.__init__`&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;Start computations.&quot;</span><span class="p">)</span>

        <span class="c1"># 1. Compute the *Features F-Measure* metric (based on *Features Recall* and *Features Predominance* metrics).</span>

        <span class="c1"># Display progress status if requested.</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;`FeaturesMaximizationMetric.__init__`&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;Compute Features F-Measure.&quot;</span><span class="p">)</span>

        <span class="c1"># Initialize variables.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_frecall</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_fpredominance</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_fmeasure</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span>
        <span class="c1"># Compute variables.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compute_features_frecall_fpredominance_fmeasure</span><span class="p">()</span>

        <span class="c1"># 2. Perform a *Features Selection* (based on *F-Measure Overall Average* comparison).</span>

        <span class="c1"># Display progress status if requested.</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;`FeaturesMaximizationMetric.__init__`&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;Compute Features Selection.&quot;</span><span class="p">)</span>

        <span class="c1"># Initialize variables.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_overall_average</span><span class="p">:</span> <span class="nb">float</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_selection</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]</span>
        <span class="c1"># Compute variables.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compute_features_selection</span><span class="p">()</span>

        <span class="c1"># 3. Compute the *Features Contrast* and *Features Activation* (based on *F-Measure Marginal Averages* comparison).</span>

        <span class="c1"># Display progress status if requested.</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;`FeaturesMaximizationMetric.__init__`&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;Compute Features Contrast.&quot;</span><span class="p">)</span>

        <span class="c1"># Initialize variables.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_marginal_averages</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_contrast</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_activation</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]]</span>
        <span class="c1"># Compute variables.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compute_features_contrast_and_activation</span><span class="p">()</span>

        <span class="c1"># Display progress status if requested.</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;`FeaturesMaximizationMetric.__init__`&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;Computations done.&quot;</span><span class="p">)</span>

    <span class="c1"># ==============================================================================</span>
    <span class="c1"># COMPUTE FEATURES F-MEASURE</span>
    <span class="c1"># ==============================================================================</span>

    <span class="k">def</span> <span class="nf">_compute_features_frecall_fpredominance_fmeasure</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute:</span>
<span class="sd">            (a) the ***Features Recall*** (cf. `self.features_frecall`),</span>
<span class="sd">            (b) the ***Features Predominance*** (cf. `self.features_fpredominance`), and</span>
<span class="sd">            (c) the ***Features F-Measure*** (cf. `self.features_fmeasure`).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">###</span>
        <span class="c1">### Temporary computations.</span>
        <span class="c1">###</span>

        <span class="c1"># Temporary variable used to store sums of all vectors weights for a given feature `f` and a given class `c`.</span>
        <span class="c1"># Needed for both Features Recall and Features Predominance computations.</span>
        <span class="n">sum_by_feature_and_classe</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">feature</span><span class="p">:</span> <span class="p">{</span><span class="n">classe</span><span class="p">:</span> <span class="mf">0.0</span> <span class="k">for</span> <span class="n">classe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span><span class="p">}</span>
            <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span>
        <span class="p">}</span>

        <span class="c1"># Temporary variable used to store sums of all vectors weights for a given feature `f` and all classes.</span>
        <span class="c1"># Needed for Features Recall computation.</span>
        <span class="n">sum_by_features</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">feature</span><span class="p">:</span> <span class="mf">0.0</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span><span class="p">}</span>

        <span class="c1"># Temporary variable used to store sums of all vectors weights for all features and a given class `c`.</span>
        <span class="c1"># Needed for Features Predominance computation.</span>
        <span class="n">sum_by_classe</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">classe</span><span class="p">:</span> <span class="mf">0.0</span> <span class="k">for</span> <span class="n">classe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span><span class="p">}</span>

        <span class="c1"># Index used to get non zero elements in the sparse matrix weights.</span>
        <span class="n">indices_x</span><span class="p">,</span> <span class="n">indices_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_vectors</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span>

        <span class="c1"># Browse non zero weights in vectors to compute all the needed sums.</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_vectors</span><span class="o">.</span><span class="n">nnz</span><span class="p">):</span>
            <span class="c1"># Get needed information (data, class/ classe, feature, vectors weight)</span>
            <span class="n">data_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">indices_x</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
            <span class="n">data_classe</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_classes</span><span class="p">[</span><span class="n">data_index</span><span class="p">]</span>
            <span class="n">feature_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">indices_y</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
            <span class="n">data_feature</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>
            <span class="n">weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_vectors</span><span class="p">[</span><span class="n">data_index</span><span class="p">,</span> <span class="n">feature_index</span><span class="p">]</span>  <span class="c1"># TODO: check if np.nan ?</span>

            <span class="c1"># Update the several sums.</span>
            <span class="n">sum_by_feature_and_classe</span><span class="p">[</span><span class="n">data_feature</span><span class="p">][</span><span class="n">data_classe</span><span class="p">]</span> <span class="o">+=</span> <span class="n">weight</span>
            <span class="n">sum_by_features</span><span class="p">[</span><span class="n">data_feature</span><span class="p">]</span> <span class="o">+=</span> <span class="n">weight</span>
            <span class="n">sum_by_classe</span><span class="p">[</span><span class="n">data_classe</span><span class="p">]</span> <span class="o">+=</span> <span class="n">weight</span>

        <span class="c1">###</span>
        <span class="c1">### Features F-Measure computation.</span>
        <span class="c1">###</span>

        <span class="c1"># Compute Features Recall.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_frecall</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">feature</span><span class="p">:</span> <span class="p">{</span>
                <span class="n">classe</span><span class="p">:</span> <span class="p">(</span>
                    <span class="mf">0.0</span>  <span class="c1"># TODO: set to np.nan ?</span>
                    <span class="k">if</span> <span class="n">sum_by_features</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span>
                    <span class="k">else</span> <span class="n">sum_by_feature_and_classe</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span> <span class="o">/</span> <span class="n">sum_by_features</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">classe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span>
        <span class="p">}</span>

        <span class="c1"># Compute Features Predominance.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_fpredominance</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">feature</span><span class="p">:</span> <span class="p">{</span>
                <span class="n">classe</span><span class="p">:</span> <span class="p">(</span>
                    <span class="mf">0.0</span>  <span class="c1"># TODO: set to np.nan ?</span>
                    <span class="k">if</span> <span class="n">sum_by_classe</span><span class="p">[</span><span class="n">classe</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span>
                    <span class="k">else</span> <span class="n">sum_by_feature_and_classe</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span> <span class="o">/</span> <span class="n">sum_by_classe</span><span class="p">[</span><span class="n">classe</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">classe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span>
        <span class="p">}</span>

        <span class="c1"># Compute Features F-Measure.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_fmeasure</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">feature</span><span class="p">:</span> <span class="p">{</span>
                <span class="n">classe</span><span class="p">:</span> <span class="p">(</span>
                    <span class="mf">0.0</span>  <span class="c1"># TODO: set to np.nan ?</span>
                    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features_frecall</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_fpredominance</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="k">else</span> <span class="p">(</span>
                        <span class="mi">2</span>
                        <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features_frecall</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_fpredominance</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">])</span>
                        <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features_frecall</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_fpredominance</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">])</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">classe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span>
        <span class="p">}</span>

    <span class="c1"># =============================================================================================</span>
    <span class="c1"># COMPUTE FEATURES SELECTION</span>
    <span class="c1"># =============================================================================================</span>

    <span class="k">def</span> <span class="nf">_compute_features_selection</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute:</span>
<span class="sd">            (d) the ***F-Measure Overall Average*** (cf. `self.features_overall_average`), and</span>
<span class="sd">            (e) the ***Features Selected*** (cf. `self.features_selection`).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">###</span>
        <span class="c1">### Features F-Measure Overall Average computation.</span>
        <span class="c1">###</span>

        <span class="c1"># Temporary variable used to store the overall sum in order to compute the overall average of Features F-Measure.</span>
        <span class="n">overall_sum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">nb_overall</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># For each feature...</span>
        <span class="k">for</span> <span class="n">feature1</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span><span class="p">:</span>
            <span class="c1"># For each classe...</span>
            <span class="k">for</span> <span class="n">classe1</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span><span class="p">:</span>
                <span class="c1"># Update the overall sum and count.</span>
                <span class="n">overall_sum</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_fmeasure</span><span class="p">[</span><span class="n">feature1</span><span class="p">][</span><span class="n">classe1</span><span class="p">]</span>
                <span class="n">nb_overall</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Compute the overall average of Features F-Measure.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_overall_average</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="k">if</span> <span class="n">nb_overall</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">overall_sum</span> <span class="o">/</span> <span class="n">nb_overall</span>  <span class="c1"># TODO: set to np.nan ?</span>

        <span class="c1">###</span>
        <span class="c1">### Features Selection computation.</span>
        <span class="c1">###</span>

        <span class="c1"># Temporary variable used store the selected features.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_selection</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Browse features to determine the selected ones.</span>
        <span class="k">for</span> <span class="n">feature2</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span><span class="p">:</span>
            <span class="c1"># Set default state of selection.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">features_selection</span><span class="p">[</span><span class="n">feature2</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># For each feature, browse class to find one for which the Features F-Measure is bigger than the overall average.</span>
            <span class="k">for</span> <span class="n">classe2</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span><span class="p">:</span>
                <span class="c1"># Check that the Feature F-Measure is bigger than the overall average.</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_fmeasure</span><span class="p">[</span><span class="n">feature2</span><span class="p">][</span><span class="n">classe2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_overall_average</span><span class="p">:</span>
                    <span class="c1"># Approve the selection and then break the loop.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">features_selection</span><span class="p">[</span><span class="n">feature2</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>

    <span class="c1"># =============================================================================================</span>
    <span class="c1"># COMPUTE FEATURES CONSTRAST AND ACTIVATION</span>
    <span class="c1"># =============================================================================================</span>

    <span class="k">def</span> <span class="nf">_compute_features_contrast_and_activation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute:</span>
<span class="sd">            (g) The ***F-Measure Marginal Averages*** (cf. `self.features_marginal_averages`), and</span>
<span class="sd">            (h) The ***Features Contrast*** (cf. `self.features_contrast`).</span>
<span class="sd">            (i) the ***Features Activation*** (cf. `self.features_activation`).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">###</span>
        <span class="c1">### Features F-Measure Marginal computation.</span>
        <span class="c1">###</span>

        <span class="c1"># Initialize the marginal average of Features F-Measure.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_marginal_averages</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Browse features to compute the averages.</span>
        <span class="k">for</span> <span class="n">feature1</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span><span class="p">:</span>
            <span class="c1"># Temporary variable used to store the marginal sum in order to compute the marginal average of Features F-Measure over the current feature.</span>
            <span class="n">sum_marginal</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">nb_marginal</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># Update the marginal sum of Features F-Measure over the current feature.</span>
            <span class="k">for</span> <span class="n">classe1</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span><span class="p">:</span>
                <span class="n">sum_marginal</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_fmeasure</span><span class="p">[</span><span class="n">feature1</span><span class="p">][</span><span class="n">classe1</span><span class="p">]</span>
                <span class="n">nb_marginal</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Compute the marginal averages of Features F-Measure over the current feature.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">features_marginal_averages</span><span class="p">[</span><span class="n">feature1</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="mf">0.0</span> <span class="k">if</span> <span class="n">nb_marginal</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">sum_marginal</span> <span class="o">/</span> <span class="n">nb_marginal</span>
            <span class="p">)</span>  <span class="c1"># TODO: set to np.nan ?</span>

        <span class="c1">###</span>
        <span class="c1">### Features Contrast computation.</span>
        <span class="c1">###</span>

        <span class="c1"># Temporary variable used to store the contrast of a feature for a class.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_contrast</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">feature2</span><span class="p">:</span> <span class="p">{</span>
                <span class="n">classe2</span><span class="p">:</span> <span class="p">(</span>
                    <span class="mf">0.0</span>  <span class="c1"># TODO: set to np.nan ?</span>
                    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features_selection</span><span class="p">[</span><span class="n">feature2</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_marginal_averages</span><span class="p">[</span><span class="n">feature2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="k">else</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features_fmeasure</span><span class="p">[</span><span class="n">feature2</span><span class="p">][</span><span class="n">classe2</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_marginal_averages</span><span class="p">[</span><span class="n">feature2</span><span class="p">])</span>
                    <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">amplification_factor</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">classe2</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">feature2</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span>
        <span class="p">}</span>

        <span class="c1">###</span>
        <span class="c1">### Features Activation computation.</span>
        <span class="c1">###</span>

        <span class="c1"># Temporary variable used store the features activation.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_activation</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">feature3</span><span class="p">:</span> <span class="p">{</span>
                <span class="n">classe3</span><span class="p">:</span> <span class="nb">bool</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">features_selection</span><span class="p">[</span><span class="n">feature3</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">True</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_contrast</span><span class="p">[</span><span class="n">feature3</span><span class="p">][</span><span class="n">classe3</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">classe3</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">feature3</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span>
        <span class="p">}</span>

    <span class="c1"># =============================================================================================</span>
    <span class="c1"># GET: MOST ACTIVATED CLASSES FOR A FEATURE</span>
    <span class="c1"># =============================================================================================</span>

    <span class="k">def</span> <span class="nf">get_most_activated_classes_by_a_feature</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">feature</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">activation_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">sort_by</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;contrast&quot;</span><span class="p">,</span> <span class="s2">&quot;fmeasure&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;contrast&quot;</span><span class="p">,</span>
        <span class="n">max_number</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the list of classes for which the requested feature is the most relevant.</span>

<span class="sd">        Args:</span>
<span class="sd">            feature (str): The feature to analyze.</span>
<span class="sd">            sort_by (Literal[&quot;contrast&quot;, &quot;fmeasure&quot;]): The sort criterion for the list of classes. Defaults to `&quot;contrast&quot;`.</span>
<span class="sd">            activation_only (bool): The option to get only activated classes. Defaults to `True`.</span>
<span class="sd">            max_number (Optional[int]): The maximum number of classes to return. Defaults to `None`.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if `feature` is not in `self.list_of_possible_features`.</span>
<span class="sd">            ValueError: if `sort_by` is not in `{&quot;contrast&quot;, &quot;fmeasure&quot;}`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[str]: The list of classes for which the requested feature is the most relevant.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">###</span>
        <span class="c1">### Check parameters.</span>
        <span class="c1">###</span>

        <span class="c1"># Check parameter `feature`.</span>
        <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The requested feature `&#39;</span><span class="si">{0}</span><span class="s2">&#39;` is unknown.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">feature</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># Check parameter `sort_by`.</span>
        <span class="k">if</span> <span class="n">sort_by</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;contrast&quot;</span><span class="p">,</span> <span class="s2">&quot;fmeasure&quot;</span><span class="p">}:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The sort option factor `sort_by` has to be in the following values: `{{&#39;contrast&#39;, &#39;fmeasure&#39;}}` (currently: &#39;</span><span class="si">{0}</span><span class="s2">&#39;).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">sort_by</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1">###</span>
        <span class="c1">### Compute the requested list.</span>
        <span class="c1">###</span>

        <span class="c1"># Define list of possible results (classe + contrast/fmeasure).</span>
        <span class="n">list_of_possible_results</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span>
                <span class="c1"># 0: the metric: contrast or fmeasure.</span>
                <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">features_contrast</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">sort_by</span> <span class="o">==</span> <span class="s2">&quot;contrast&quot;</span>
                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_fmeasure</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span>
                <span class="p">),</span>
                <span class="c1"># 1: the classe.</span>
                <span class="n">classe</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">classe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">activation_only</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_activation</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="c1"># Return top classes sorted by requested metric.</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">activated_classe</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">activated_classe</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
                <span class="n">list_of_possible_results</span><span class="p">,</span>
                <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">][:</span><span class="n">max_number</span><span class="p">]</span>

    <span class="c1"># =============================================================================================</span>
    <span class="c1"># GET: MOST ACTIVATED FEATURES FOR A CLASSE</span>
    <span class="c1"># =============================================================================================</span>

    <span class="k">def</span> <span class="nf">get_most_active_features_by_a_classe</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">classe</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">activation_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">sort_by</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;contrast&quot;</span><span class="p">,</span> <span class="s2">&quot;fmeasure&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;contrast&quot;</span><span class="p">,</span>
        <span class="n">max_number</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the list of features which are the most relevant for the requested classe.</span>

<span class="sd">        Args:</span>
<span class="sd">            classe (str): The classe to analyze.</span>
<span class="sd">            sort_by (Literal[&quot;contrast&quot;, &quot;fmeasure&quot;]): The sort criterion for the list of features. Defaults to `&quot;contrast&quot;`.</span>
<span class="sd">            activation_only (bool): The option to get only active features. Defaults to `True`.</span>
<span class="sd">            max_number (Optional[int]): The maximum number of features to return. Defaults to `None`.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if `classe` is not in `self.list_of_possible_classes`.</span>
<span class="sd">            ValueError: if `sort_by` is not in `{&quot;contrast&quot;, &quot;fmeasure&quot;}`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[str]: The list of features which are the most relevant for the requested classe.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">###</span>
        <span class="c1">### Check parameters.</span>
        <span class="c1">###</span>

        <span class="c1"># Check parameter `feature`.</span>
        <span class="k">if</span> <span class="n">classe</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The requested classe `&#39;</span><span class="si">{0}</span><span class="s2">&#39;` is unknown.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">classe</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># Check parameter `sort_by`.</span>
        <span class="k">if</span> <span class="n">sort_by</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;contrast&quot;</span><span class="p">,</span> <span class="s2">&quot;fmeasure&quot;</span><span class="p">}:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The sort option factor `sort_by` has to be in the following values: `{{&#39;contrast&#39;, &#39;fmeasure&#39;}}` (currently: &#39;</span><span class="si">{0}</span><span class="s2">&#39;).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">sort_by</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1">###</span>
        <span class="c1">### Compute the requested list.</span>
        <span class="c1">###</span>

        <span class="c1"># Define list of possible results (feature + contrast/fmeasure).</span>
        <span class="n">list_of_possible_results</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span>
                <span class="c1"># 0: the metric: contrast or fmeasure.</span>
                <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">features_contrast</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">sort_by</span> <span class="o">==</span> <span class="s2">&quot;contrast&quot;</span>
                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_fmeasure</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span>
                <span class="p">),</span>
                <span class="c1"># 1: the feature.</span>
                <span class="n">feature</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">activation_only</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_activation</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="c1"># Return top features sorted by requested metric.</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">active_feature</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">active_feature</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
                <span class="n">list_of_possible_results</span><span class="p">,</span>
                <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">][:</span><span class="n">max_number</span><span class="p">]</span>

    <span class="c1"># =============================================================================================</span>
    <span class="c1"># COMPARE: WITH AN OTHER FMC</span>
    <span class="c1"># =============================================================================================</span>

    <span class="k">def</span> <span class="nf">compare</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fmc_reference</span><span class="p">:</span> <span class="s2">&quot;FeaturesMaximizationMetric&quot;</span><span class="p">,</span>
        <span class="n">rounded</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gives a similarity score in agreement with a reference FMC modelization.</span>
<span class="sd">        The similarity score computation is based on common metrics on clustering (homogeneity, completeness, v_measure),</span>
<span class="sd">        where each FMC modelization is represented by the Features Activation of their vector features.</span>
<span class="sd">        In order to be able to compute these similarity, data classes can be different, but vector features must be the same in both FMC modelization.</span>


<span class="sd">        Args:</span>
<span class="sd">            fmc_reference (FeaturesMaximizationMetric): Another Features Maximization modelization used as reference for the comparison.</span>
<span class="sd">            rounded (Optional[int]): The option to round the result to counter log approximation. Defaults to `None`.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if `list_of_possible_features` are different.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[float, float, float]: Computation</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">###</span>
        <span class="c1">### Check parameters.</span>
        <span class="c1">###</span>

        <span class="c1"># Check list_of_possible_features equality.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span> <span class="o">!=</span> <span class="n">fmc_reference</span><span class="o">.</span><span class="n">list_of_possible_features</span><span class="p">:</span>
            <span class="n">list_of_in_excess_features</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">feature</span>
                <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span>
                <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">fmc_reference</span><span class="o">.</span><span class="n">list_of_possible_features</span>
            <span class="p">]</span>
            <span class="n">list_of_missing_features</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">feature</span>
                <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">fmc_reference</span><span class="o">.</span><span class="n">list_of_possible_features</span>
                <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span>
            <span class="p">]</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The list of features `list_of_possible_features` must be the same for both FMC modelization. +: </span><span class="si">{0}</span><span class="s2">, -: </span><span class="si">{1}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="nb">str</span><span class="p">(</span><span class="n">list_of_in_excess_features</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">list_of_missing_features</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1">###</span>
        <span class="c1">### Format Features Activation as classification label of features.</span>
        <span class="c1">###</span>

        <span class="c1"># Initialize</span>
        <span class="n">list_of_self_features_activations</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">list_of_reference_features_activations</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Define default value if feature not activated.</span>
        <span class="c1"># NB: we can&#39;t set a fixed value in case this value is in the list of possible classes...</span>
        <span class="c1"># Example: can&#39;t set `&quot;&quot;` or `&quot;None&quot;` in case self.list_of_possible_classes==[&quot;A&quot;, &quot;&quot;] and fmc_reference.list_of_possible_classes==[&quot;B&quot;, &quot;None&quot;].</span>
        <span class="n">default_label_if_feature_not_activated</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;NOT_ACTIVATED:</span><span class="si">{possible_classe}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">possible_classe</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span> <span class="o">+</span> <span class="n">fmc_reference</span><span class="o">.</span><span class="n">list_of_possible_classes</span>
        <span class="p">)</span>

        <span class="c1"># Browse activated features to compare Features Activation.</span>
        <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">fmc_reference</span><span class="o">.</span><span class="n">list_of_possible_features</span><span class="p">:</span>
            <span class="c1"># Get Features Activation.</span>
            <span class="n">list_of_most_activated_classes_for_feature_in_self</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span>
                <span class="nb">str</span>
            <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_most_activated_classes_by_a_feature</span><span class="p">(</span>
                <span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">list_of_most_activated_classes_for_feature_in_reference</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span>
                <span class="nb">str</span>
            <span class="p">]</span> <span class="o">=</span> <span class="n">fmc_reference</span><span class="o">.</span><span class="n">get_most_activated_classes_by_a_feature</span><span class="p">(</span>
                <span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># TODO: Skip if feature is not activated in both modelization.</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">list_of_most_activated_classes_for_feature_in_self</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span>
                <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_most_activated_classes_for_feature_in_reference</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span>
            <span class="p">):</span>
                <span class="k">continue</span>

            <span class="c1"># Format Feature Activation as classification label. Set to `-1` if not activated.</span>
            <span class="n">list_of_self_features_activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">list_of_most_activated_classes_for_feature_in_self</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_most_activated_classes_for_feature_in_self</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
                <span class="k">else</span> <span class="n">default_label_if_feature_not_activated</span>
            <span class="p">)</span>
            <span class="n">list_of_reference_features_activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">list_of_most_activated_classes_for_feature_in_reference</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_most_activated_classes_for_feature_in_reference</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
                <span class="k">else</span> <span class="n">default_label_if_feature_not_activated</span>
            <span class="p">)</span>

        <span class="c1">###</span>
        <span class="c1">### Compute FMC modelizations similarity.</span>
        <span class="c1">###</span>

        <span class="c1"># Compute standard metrics for clustering.</span>
        <span class="n">homogeneity</span><span class="p">:</span> <span class="nb">float</span>
        <span class="n">completeness</span><span class="p">:</span> <span class="nb">float</span>
        <span class="n">v_measure</span><span class="p">:</span> <span class="nb">float</span>
        <span class="n">homogeneity</span><span class="p">,</span> <span class="n">completeness</span><span class="p">,</span> <span class="n">v_measure</span> <span class="o">=</span> <span class="n">homogeneity_completeness_v_measure</span><span class="p">(</span>
            <span class="n">labels_pred</span><span class="o">=</span><span class="n">list_of_self_features_activations</span><span class="p">,</span>
            <span class="n">labels_true</span><span class="o">=</span><span class="n">list_of_reference_features_activations</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Round the results.</span>
        <span class="k">if</span> <span class="n">rounded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">homogeneity</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">homogeneity</span><span class="p">,</span> <span class="n">rounded</span><span class="p">)</span>
            <span class="n">completeness</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">completeness</span><span class="p">,</span> <span class="n">rounded</span><span class="p">)</span>
            <span class="n">v_measure</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">v_measure</span><span class="p">,</span> <span class="n">rounded</span><span class="p">)</span>

        <span class="c1"># Return values.</span>
        <span class="k">return</span> <span class="n">homogeneity</span><span class="p">,</span> <span class="n">completeness</span><span class="p">,</span> <span class="n">v_measure</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">data_vectors</span><span class="p">,</span> <span class="n">data_classes</span><span class="p">,</span> <span class="n">list_of_possible_features</span><span class="p">,</span> <span class="n">amplification_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>The constructor for <code>FeaturesMaximizationMetric</code> class.
It applies the several steps of <strong><em>Feature Maximization</em></strong>:
    1. Compute the <strong><em>Features F-Measure</em></strong> metric (based on <strong><em>Features Recall</em></strong> and <strong><em>Features Predominance</em></strong> metrics).
    2. Compute the <strong><em>Features Selection</em></strong> (based on <strong><em>F-Measure Overall Average</em></strong> comparison).
    3. Compute the <strong><em>Features Contrast</em></strong> and <strong><em>Features Activation</em></strong> (based on <strong><em>F-Measure Marginal Averages</em></strong> comparison).</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>data_vectors</code></td>
          <td>
                <code>scipy.<span title="scipy.sparse">sparse</span>.<span title="scipy.sparse.csr_matrix">csr_matrix</span></code>
          </td>
          <td><p>A sparse matrix representing the vector of each data (i.e. <code>data_vectors[d,f]</code> is the weight of data <code>d</code> for feature <code>f</code>).</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>data_classes</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>A list representing the class of each data (i.e. <code>data_classes[d]</code> is the class of data <code>d</code>).</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>list_of_possible_features</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>A list of existing vectors features.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>amplification_factor</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>A positive integer called "amplification factor" aimed at emphasize the feature contrast. Defaults to <code>1</code>.</p></td>
          <td>
                <code>1</code>
          </td>
        </tr>
        <tr>
          <td><code>verbose</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>An option to display progress status of computations. Defaults to <code>False</code>.</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td><p>if <code>data_vectors</code> and <code>data_classes</code> have inconsistent shapes.</p></td>
        </tr>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td><p>if <code>data_vectors</code> and <code>list_of_possible_features</code> have inconsistent shapes.</p></td>
        </tr>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td><p>if <code>amplification_factor</code> is not a positive integer.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>cognitivefactory\features_maximization_metric\fmc.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data_vectors</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
    <span class="n">data_classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">list_of_possible_features</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">amplification_factor</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The constructor for `FeaturesMaximizationMetric` class.</span>
<span class="sd">    It applies the several steps of ***Feature Maximization***:</span>
<span class="sd">        1. Compute the ***Features F-Measure*** metric (based on ***Features Recall*** and ***Features Predominance*** metrics).</span>
<span class="sd">        2. Compute the ***Features Selection*** (based on ***F-Measure Overall Average*** comparison).</span>
<span class="sd">        3. Compute the ***Features Contrast*** and ***Features Activation*** (based on ***F-Measure Marginal Averages*** comparison).</span>

<span class="sd">    Args:</span>
<span class="sd">        data_vectors (scipy.sparse.csr_matrix): A sparse matrix representing the vector of each data (i.e. `data_vectors[d,f]` is the weight of data `d` for feature `f`).</span>
<span class="sd">        data_classes (List[str]): A list representing the class of each data (i.e. `data_classes[d]` is the class of data `d`).</span>
<span class="sd">        list_of_possible_features (List[str]): A list of existing vectors features.</span>
<span class="sd">        amplification_factor (int, optional): A positive integer called &quot;amplification factor&quot; aimed at emphasize the feature contrast. Defaults to `1`.</span>
<span class="sd">        verbose (bool): An option to display progress status of computations. Defaults to `False`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if `data_vectors` and `data_classes` have inconsistent shapes.</span>
<span class="sd">        ValueError: if `data_vectors` and `list_of_possible_features` have inconsistent shapes.</span>
<span class="sd">        ValueError: if `amplification_factor` is not a positive integer.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">###</span>
    <span class="c1">### Check parameters.</span>
    <span class="c1">###</span>

    <span class="c1"># Display progress status if requested.</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;`FeaturesMaximizationMetric.__init__`&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;Check parameters.&quot;</span><span class="p">)</span>

    <span class="c1"># Check data size.</span>
    <span class="k">if</span> <span class="n">data_vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_classes</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The vectors `data_vectors` and the list of classes `data_classes` have inconsistent shapes (currently: &#39;</span><span class="si">{0}</span><span class="s2">&#39; vs &#39;</span><span class="si">{1}</span><span class="s2">&#39;).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">data_vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">data_classes</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Check features size.</span>
    <span class="k">if</span> <span class="n">data_vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_possible_features</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The vectors `data_vectors` and the list of features `list_of_possible_features` have inconsistent shapes (currently: &#39;</span><span class="si">{0}</span><span class="s2">&#39; vs &#39;</span><span class="si">{1}</span><span class="s2">&#39;).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">data_vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">list_of_possible_features</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Check amplification factor.</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">amplification_factor</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span> <span class="ow">or</span> <span class="n">amplification_factor</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The amplification factor `amplification_factor` has to be a positive integer (currently: &#39;</span><span class="si">{0}</span><span class="s2">&#39;).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">amplification_factor</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="c1">###</span>
    <span class="c1">### Store parameters.</span>
    <span class="c1">###</span>

    <span class="c1"># Display progress status if requested.</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;`FeaturesMaximizationMetric.__init__`&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;Store parameters.&quot;</span><span class="p">)</span>

    <span class="c1"># Store data information.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data_vectors</span><span class="p">:</span> <span class="n">csr_matrix</span> <span class="o">=</span> <span class="n">data_vectors</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data_classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_classes</span>
    <span class="c1"># Store features and classes lists.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">list_of_possible_features</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">data_classes</span><span class="p">))</span>
    <span class="c1"># Store amplification factor.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">amplification_factor</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">amplification_factor</span>

    <span class="c1">###</span>
    <span class="c1">### Compute Features Maximization Metric.</span>
    <span class="c1">###</span>

    <span class="c1"># Display progress status if requested.</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;`FeaturesMaximizationMetric.__init__`&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;Start computations.&quot;</span><span class="p">)</span>

    <span class="c1"># 1. Compute the *Features F-Measure* metric (based on *Features Recall* and *Features Predominance* metrics).</span>

    <span class="c1"># Display progress status if requested.</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;`FeaturesMaximizationMetric.__init__`&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;Compute Features F-Measure.&quot;</span><span class="p">)</span>

    <span class="c1"># Initialize variables.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_frecall</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_fpredominance</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_fmeasure</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span>
    <span class="c1"># Compute variables.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_compute_features_frecall_fpredominance_fmeasure</span><span class="p">()</span>

    <span class="c1"># 2. Perform a *Features Selection* (based on *F-Measure Overall Average* comparison).</span>

    <span class="c1"># Display progress status if requested.</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;`FeaturesMaximizationMetric.__init__`&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;Compute Features Selection.&quot;</span><span class="p">)</span>

    <span class="c1"># Initialize variables.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_overall_average</span><span class="p">:</span> <span class="nb">float</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_selection</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]</span>
    <span class="c1"># Compute variables.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_compute_features_selection</span><span class="p">()</span>

    <span class="c1"># 3. Compute the *Features Contrast* and *Features Activation* (based on *F-Measure Marginal Averages* comparison).</span>

    <span class="c1"># Display progress status if requested.</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;`FeaturesMaximizationMetric.__init__`&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;Compute Features Contrast.&quot;</span><span class="p">)</span>

    <span class="c1"># Initialize variables.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_marginal_averages</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_contrast</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_activation</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]]</span>
    <span class="c1"># Compute variables.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_compute_features_contrast_and_activation</span><span class="p">()</span>

    <span class="c1"># Display progress status if requested.</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;`FeaturesMaximizationMetric.__init__`&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;Computations done.&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.compare" class="doc doc-heading">
<code class="highlight language-python"><span class="n">compare</span><span class="p">(</span><span class="n">fmc_reference</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.compare" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Gives a similarity score in agreement with a reference FMC modelization.
The similarity score computation is based on common metrics on clustering (homogeneity, completeness, v_measure),
where each FMC modelization is represented by the Features Activation of their vector features.
In order to be able to compute these similarity, data classes can be different, but vector features must be the same in both FMC modelization.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>fmc_reference</code></td>
          <td>
                <code><a class="autorefs autorefs-internal" title="cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric" href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric">FeaturesMaximizationMetric</a></code>
          </td>
          <td><p>Another Features Maximization modelization used as reference for the comparison.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>rounded</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[int]</code>
          </td>
          <td><p>The option to round the result to counter log approximation. Defaults to <code>None</code>.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td><p>if <code>list_of_possible_features</code> are different.</p></td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="typing.Tuple">Tuple</span>[float, float, float]</code>
          </td>
          <td><p>Tuple[float, float, float]: Computation</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>cognitivefactory\features_maximization_metric\fmc.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compare</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">fmc_reference</span><span class="p">:</span> <span class="s2">&quot;FeaturesMaximizationMetric&quot;</span><span class="p">,</span>
    <span class="n">rounded</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Gives a similarity score in agreement with a reference FMC modelization.</span>
<span class="sd">    The similarity score computation is based on common metrics on clustering (homogeneity, completeness, v_measure),</span>
<span class="sd">    where each FMC modelization is represented by the Features Activation of their vector features.</span>
<span class="sd">    In order to be able to compute these similarity, data classes can be different, but vector features must be the same in both FMC modelization.</span>


<span class="sd">    Args:</span>
<span class="sd">        fmc_reference (FeaturesMaximizationMetric): Another Features Maximization modelization used as reference for the comparison.</span>
<span class="sd">        rounded (Optional[int]): The option to round the result to counter log approximation. Defaults to `None`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if `list_of_possible_features` are different.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[float, float, float]: Computation</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">###</span>
    <span class="c1">### Check parameters.</span>
    <span class="c1">###</span>

    <span class="c1"># Check list_of_possible_features equality.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span> <span class="o">!=</span> <span class="n">fmc_reference</span><span class="o">.</span><span class="n">list_of_possible_features</span><span class="p">:</span>
        <span class="n">list_of_in_excess_features</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">feature</span>
            <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span>
            <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">fmc_reference</span><span class="o">.</span><span class="n">list_of_possible_features</span>
        <span class="p">]</span>
        <span class="n">list_of_missing_features</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">feature</span>
            <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">fmc_reference</span><span class="o">.</span><span class="n">list_of_possible_features</span>
            <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span>
        <span class="p">]</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The list of features `list_of_possible_features` must be the same for both FMC modelization. +: </span><span class="si">{0}</span><span class="s2">, -: </span><span class="si">{1}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="nb">str</span><span class="p">(</span><span class="n">list_of_in_excess_features</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">list_of_missing_features</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="c1">###</span>
    <span class="c1">### Format Features Activation as classification label of features.</span>
    <span class="c1">###</span>

    <span class="c1"># Initialize</span>
    <span class="n">list_of_self_features_activations</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">list_of_reference_features_activations</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Define default value if feature not activated.</span>
    <span class="c1"># NB: we can&#39;t set a fixed value in case this value is in the list of possible classes...</span>
    <span class="c1"># Example: can&#39;t set `&quot;&quot;` or `&quot;None&quot;` in case self.list_of_possible_classes==[&quot;A&quot;, &quot;&quot;] and fmc_reference.list_of_possible_classes==[&quot;B&quot;, &quot;None&quot;].</span>
    <span class="n">default_label_if_feature_not_activated</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;NOT_ACTIVATED:</span><span class="si">{possible_classe}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">possible_classe</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span> <span class="o">+</span> <span class="n">fmc_reference</span><span class="o">.</span><span class="n">list_of_possible_classes</span>
    <span class="p">)</span>

    <span class="c1"># Browse activated features to compare Features Activation.</span>
    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">fmc_reference</span><span class="o">.</span><span class="n">list_of_possible_features</span><span class="p">:</span>
        <span class="c1"># Get Features Activation.</span>
        <span class="n">list_of_most_activated_classes_for_feature_in_self</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span>
            <span class="nb">str</span>
        <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_most_activated_classes_by_a_feature</span><span class="p">(</span>
            <span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">list_of_most_activated_classes_for_feature_in_reference</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span>
            <span class="nb">str</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">fmc_reference</span><span class="o">.</span><span class="n">get_most_activated_classes_by_a_feature</span><span class="p">(</span>
            <span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># TODO: Skip if feature is not activated in both modelization.</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">list_of_most_activated_classes_for_feature_in_self</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_most_activated_classes_for_feature_in_reference</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span>
        <span class="p">):</span>
            <span class="k">continue</span>

        <span class="c1"># Format Feature Activation as classification label. Set to `-1` if not activated.</span>
        <span class="n">list_of_self_features_activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">list_of_most_activated_classes_for_feature_in_self</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_most_activated_classes_for_feature_in_self</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="k">else</span> <span class="n">default_label_if_feature_not_activated</span>
        <span class="p">)</span>
        <span class="n">list_of_reference_features_activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">list_of_most_activated_classes_for_feature_in_reference</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_most_activated_classes_for_feature_in_reference</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="k">else</span> <span class="n">default_label_if_feature_not_activated</span>
        <span class="p">)</span>

    <span class="c1">###</span>
    <span class="c1">### Compute FMC modelizations similarity.</span>
    <span class="c1">###</span>

    <span class="c1"># Compute standard metrics for clustering.</span>
    <span class="n">homogeneity</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">completeness</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">v_measure</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">homogeneity</span><span class="p">,</span> <span class="n">completeness</span><span class="p">,</span> <span class="n">v_measure</span> <span class="o">=</span> <span class="n">homogeneity_completeness_v_measure</span><span class="p">(</span>
        <span class="n">labels_pred</span><span class="o">=</span><span class="n">list_of_self_features_activations</span><span class="p">,</span>
        <span class="n">labels_true</span><span class="o">=</span><span class="n">list_of_reference_features_activations</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Round the results.</span>
    <span class="k">if</span> <span class="n">rounded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">homogeneity</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">homogeneity</span><span class="p">,</span> <span class="n">rounded</span><span class="p">)</span>
        <span class="n">completeness</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">completeness</span><span class="p">,</span> <span class="n">rounded</span><span class="p">)</span>
        <span class="n">v_measure</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">v_measure</span><span class="p">,</span> <span class="n">rounded</span><span class="p">)</span>

    <span class="c1"># Return values.</span>
    <span class="k">return</span> <span class="n">homogeneity</span><span class="p">,</span> <span class="n">completeness</span><span class="p">,</span> <span class="n">v_measure</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.get_most_activated_classes_by_a_feature" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_most_activated_classes_by_a_feature</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">activation_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sort_by</span><span class="o">=</span><span class="s1">&#39;contrast&#39;</span><span class="p">,</span> <span class="n">max_number</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.get_most_activated_classes_by_a_feature" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Get the list of classes for which the requested feature is the most relevant.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>feature</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>The feature to analyze.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>sort_by</code></td>
          <td>
                <code><span title="typing.Literal">Literal</span>[&#39;contrast&#39;, &#39;fmeasure&#39;]</code>
          </td>
          <td><p>The sort criterion for the list of classes. Defaults to <code>"contrast"</code>.</p></td>
          <td>
                <code>&#39;contrast&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>activation_only</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>The option to get only activated classes. Defaults to <code>True</code>.</p></td>
          <td>
                <code>True</code>
          </td>
        </tr>
        <tr>
          <td><code>max_number</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[int]</code>
          </td>
          <td><p>The maximum number of classes to return. Defaults to <code>None</code>.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td><p>if <code>feature</code> is not in <code>self.list_of_possible_features</code>.</p></td>
        </tr>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td><p>if <code>sort_by</code> is not in <code>{"contrast", "fmeasure"}</code>.</p></td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>List[str]: The list of classes for which the requested feature is the most relevant.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>cognitivefactory\features_maximization_metric\fmc.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_most_activated_classes_by_a_feature</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">feature</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">activation_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">sort_by</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;contrast&quot;</span><span class="p">,</span> <span class="s2">&quot;fmeasure&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;contrast&quot;</span><span class="p">,</span>
    <span class="n">max_number</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the list of classes for which the requested feature is the most relevant.</span>

<span class="sd">    Args:</span>
<span class="sd">        feature (str): The feature to analyze.</span>
<span class="sd">        sort_by (Literal[&quot;contrast&quot;, &quot;fmeasure&quot;]): The sort criterion for the list of classes. Defaults to `&quot;contrast&quot;`.</span>
<span class="sd">        activation_only (bool): The option to get only activated classes. Defaults to `True`.</span>
<span class="sd">        max_number (Optional[int]): The maximum number of classes to return. Defaults to `None`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if `feature` is not in `self.list_of_possible_features`.</span>
<span class="sd">        ValueError: if `sort_by` is not in `{&quot;contrast&quot;, &quot;fmeasure&quot;}`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[str]: The list of classes for which the requested feature is the most relevant.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">###</span>
    <span class="c1">### Check parameters.</span>
    <span class="c1">###</span>

    <span class="c1"># Check parameter `feature`.</span>
    <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The requested feature `&#39;</span><span class="si">{0}</span><span class="s2">&#39;` is unknown.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">feature</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Check parameter `sort_by`.</span>
    <span class="k">if</span> <span class="n">sort_by</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;contrast&quot;</span><span class="p">,</span> <span class="s2">&quot;fmeasure&quot;</span><span class="p">}:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The sort option factor `sort_by` has to be in the following values: `{{&#39;contrast&#39;, &#39;fmeasure&#39;}}` (currently: &#39;</span><span class="si">{0}</span><span class="s2">&#39;).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">sort_by</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="c1">###</span>
    <span class="c1">### Compute the requested list.</span>
    <span class="c1">###</span>

    <span class="c1"># Define list of possible results (classe + contrast/fmeasure).</span>
    <span class="n">list_of_possible_results</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span>
            <span class="c1"># 0: the metric: contrast or fmeasure.</span>
            <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">features_contrast</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">sort_by</span> <span class="o">==</span> <span class="s2">&quot;contrast&quot;</span>
                <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_fmeasure</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span>
            <span class="p">),</span>
            <span class="c1"># 1: the classe.</span>
            <span class="n">classe</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">classe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">activation_only</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_activation</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="c1"># Return top classes sorted by requested metric.</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="n">activated_classe</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">activated_classe</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="n">list_of_possible_results</span><span class="p">,</span>
            <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">][:</span><span class="n">max_number</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.get_most_active_features_by_a_classe" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_most_active_features_by_a_classe</span><span class="p">(</span><span class="n">classe</span><span class="p">,</span> <span class="n">activation_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sort_by</span><span class="o">=</span><span class="s1">&#39;contrast&#39;</span><span class="p">,</span> <span class="n">max_number</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.get_most_active_features_by_a_classe" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Get the list of features which are the most relevant for the requested classe.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>classe</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>The classe to analyze.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>sort_by</code></td>
          <td>
                <code><span title="typing.Literal">Literal</span>[&#39;contrast&#39;, &#39;fmeasure&#39;]</code>
          </td>
          <td><p>The sort criterion for the list of features. Defaults to <code>"contrast"</code>.</p></td>
          <td>
                <code>&#39;contrast&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>activation_only</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>The option to get only active features. Defaults to <code>True</code>.</p></td>
          <td>
                <code>True</code>
          </td>
        </tr>
        <tr>
          <td><code>max_number</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[int]</code>
          </td>
          <td><p>The maximum number of features to return. Defaults to <code>None</code>.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td><p>if <code>classe</code> is not in <code>self.list_of_possible_classes</code>.</p></td>
        </tr>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td><p>if <code>sort_by</code> is not in <code>{"contrast", "fmeasure"}</code>.</p></td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>List[str]: The list of features which are the most relevant for the requested classe.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>cognitivefactory\features_maximization_metric\fmc.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_most_active_features_by_a_classe</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">classe</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">activation_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">sort_by</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;contrast&quot;</span><span class="p">,</span> <span class="s2">&quot;fmeasure&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;contrast&quot;</span><span class="p">,</span>
    <span class="n">max_number</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the list of features which are the most relevant for the requested classe.</span>

<span class="sd">    Args:</span>
<span class="sd">        classe (str): The classe to analyze.</span>
<span class="sd">        sort_by (Literal[&quot;contrast&quot;, &quot;fmeasure&quot;]): The sort criterion for the list of features. Defaults to `&quot;contrast&quot;`.</span>
<span class="sd">        activation_only (bool): The option to get only active features. Defaults to `True`.</span>
<span class="sd">        max_number (Optional[int]): The maximum number of features to return. Defaults to `None`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if `classe` is not in `self.list_of_possible_classes`.</span>
<span class="sd">        ValueError: if `sort_by` is not in `{&quot;contrast&quot;, &quot;fmeasure&quot;}`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[str]: The list of features which are the most relevant for the requested classe.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">###</span>
    <span class="c1">### Check parameters.</span>
    <span class="c1">###</span>

    <span class="c1"># Check parameter `feature`.</span>
    <span class="k">if</span> <span class="n">classe</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_classes</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The requested classe `&#39;</span><span class="si">{0}</span><span class="s2">&#39;` is unknown.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">classe</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Check parameter `sort_by`.</span>
    <span class="k">if</span> <span class="n">sort_by</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;contrast&quot;</span><span class="p">,</span> <span class="s2">&quot;fmeasure&quot;</span><span class="p">}:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The sort option factor `sort_by` has to be in the following values: `{{&#39;contrast&#39;, &#39;fmeasure&#39;}}` (currently: &#39;</span><span class="si">{0}</span><span class="s2">&#39;).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">sort_by</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="c1">###</span>
    <span class="c1">### Compute the requested list.</span>
    <span class="c1">###</span>

    <span class="c1"># Define list of possible results (feature + contrast/fmeasure).</span>
    <span class="n">list_of_possible_results</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span>
            <span class="c1"># 0: the metric: contrast or fmeasure.</span>
            <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">features_contrast</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">sort_by</span> <span class="o">==</span> <span class="s2">&quot;contrast&quot;</span>
                <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_fmeasure</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span>
            <span class="p">),</span>
            <span class="c1"># 1: the feature.</span>
            <span class="n">feature</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_possible_features</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">activation_only</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_activation</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="n">classe</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="c1"># Return top features sorted by requested metric.</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="n">active_feature</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">active_feature</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="n">list_of_possible_results</span><span class="p">,</span>
            <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">][:</span><span class="n">max_number</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>





                
              </article>
            </div>
          
          
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </a>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/erwanschild" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.top"], "search": "../../../../assets/javascripts/workers/search.db81ec45.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.4b2c34cd.min.js"></script>
      
    
  </body>
</html>