{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Features Maximization Metric","text":"<p>Implementation of Features Maximization Metric, an unbiased metric aimed at estimate the quality of an unsupervised classification.</p>"},{"location":"#quick-description","title":"Quick description","text":"<p>Features Maximization (<code>FMC</code>) is a features selection method described in <code>Lamirel J.-C., Cuxac P., Hajlaoui K., A new approach for feature selection based on quality metric, Advances in Knowledge Discovery and Management, 6 (665), Springer.</code></p> <p>This metric is computed by applying the following steps:</p> <ol> <li> <p>Compute the Features F-Measure metric (based on Features Recall and Features Predominance metrics).</p> <p>(a) The Features Recall <code>FR[f][c]</code> for a given class <code>c</code> and a given feature <code>f</code> is the ratio between the sum of the vectors weights of the feature <code>f</code> for data in class <code>c</code> and the sum of all vectors weights of feature <code>f</code> for all data. It answers the question: \"Can the feature <code>f</code> distinguish the class <code>c</code> from other classes <code>c'</code> ?\"</p> <p>(b) The Features Predominance <code>FP[f][c]</code> for a given class <code>c</code> and a given feature <code>f</code> is the ratio between the sum of the vectors weights of the feature <code>f</code> for data in class <code>c</code> and the sum of all vectors weights of all feature <code>f'</code> for data in class <code>c</code>. It answers the question: \"Can the feature <code>f</code> better identify the class <code>c</code> than the other features <code>f'</code> ?\"</p> <p>(c) The Features F-Measure <code>FM[f][c]</code> for a given class <code>c</code> and a given feature <code>f</code> is the harmonic mean of the Features Recall (a) and the Features Predominance (c). It answers the question: \"How much information does the feature <code>f</code> contain about the class <code>c</code> ?\"</p> </li> <li> <p>Compute the Features Selection (based on F-Measure Overall Average comparison).</p> <p>(d) The F-Measure Overall Average is the average of Features F-Measure (c) for all classes <code>c</code> and for all features <code>f</code>. It answers the question: \"What are the mean of information contained by features in all classes ?\"</p> <p>(e) A feature <code>f</code> is Selected if and only if it exist at least one class <code>c</code> for which the Features F-Measure (c) <code>FM[f][c]</code> is bigger than the F-Measure Overall Average (d). It answers the question: \"What are the features which contain more information than the mean of information in the dataset ?\"</p> <p>(f) A Feature <code>f</code> is Deleted if and only if the Features F-Measure (c) <code>FM[f][c]</code> is always lower than the F-Measure Overall Average (d) for each class <code>c</code>. It answers the question: \"What are the features which do not contain more information than the mean of information in the dataset ?\"</p> </li> <li> <p>Compute the Features Contrast and Features Activation (based on F-Measure Marginal Averages comparison).</p> <p>(g) The F-Measure Marginal Averages for a given feature <code>f</code> is the average of Features F-Measure (c) for all classes <code>c</code> and for the given feature <code>f</code>. It answers the question: \"What are the mean of information contained by the feature <code>f</code> in all classes ?\"</p> <p>(h) The Features Contrast <code>FC[f][c]</code> for a given class <code>c</code> and a given selected feature <code>f</code> is the ratio between the Features F-Measure (c) <code>FM[f][c]</code> and the F-Measure Marginal Averages (g) for selected feature f put to the power of an Amplification Factor. It answers the question: \"How relevant is the feature <code>f</code> to distinguish the class <code>c</code> ?\"</p> <p>(i) A selected Feature <code>f</code> is Active for a given class <code>c</code> if and only if the Features Contrast (h) <code>FC[f][c]</code> is bigger than <code>1.0</code>. It answers the question : \"For which classes a selected feature <code>f</code> is relevant ?\"</p> </li> </ol> <p>This metric is an efficient method to:</p> <ul> <li>identify relevant features of a dataset modelization;</li> <li>describe association between vectors features and data classes;</li> <li>increase contrast between data classes.</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Main documentation</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Features Maximization Metric requires <code>Python</code> 3.8 or above.</p> <p>To install with <code>pip</code>:</p> <pre><code># install package\npython3 -m pip install cognitivefactory-features-maximization-metric\n</code></pre> <p>To install with <code>pipx</code>:</p> <pre><code># install pipx\npython3 -m pip install --user pipx\n\n# install package\npipx install --python python3 cognitivefactory-features-maximization-metric\n</code></pre>"},{"location":"#development","title":"Development","text":"<p>To work on this project or contribute to it, please read:</p> <ul> <li>the Copier PDM template documentation ;</li> <li>the Contributing page for environment setup and development help ;</li> <li>the Code of Conduct page for contribution rules.</li> </ul>"},{"location":"#references","title":"References","text":"<ul> <li>Features Maximization Metric: <code>Lamirel J.-C., Cuxac P., Hajlaoui K., A new approach for feature selection based on quality metric, Advances in Knowledge Discovery and Management, 6 (665), Springer.</code></li> <li>V-Measure: <code>Rosenberg, Andrew &amp; Hirschberg, Julia. (2007). V-Measure: A Conditional Entropy-Based External Cluster Evaluation Measure. 410-420.</code></li> </ul>"},{"location":"#how-to-cite","title":"How to cite","text":"<p><code>Schild, E. (2023). cognitivefactory/features-maximization-metric. Zenodo. https://doi.org/10.5281/zenodo.7646382.</code></p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#011-2023-02-16","title":"0.1.1 - 2023-02-16","text":"<p>Compare with 0.1.0</p>"},{"location":"changelog/#build","title":"Build","text":"<ul> <li>fix git-changelog dependancy (a6b6684 by SCHILD Erwan).</li> </ul>"},{"location":"changelog/#010-2023-02-16","title":"0.1.0 - 2023-02-16","text":"<p>Compare with first commit</p>"},{"location":"changelog/#build_1","title":"Build","text":"<ul> <li>configure project template (741b82c by SCHILD Erwan).</li> <li>add .gitignore (9e57355 by SCHILD Erwan).</li> </ul>"},{"location":"changelog/#features","title":"Features","text":"<ul> <li>implement Feature Maximization Metric (44554c3 by SCHILD Erwan).</li> </ul>"},{"location":"code_of_conduct/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"code_of_conduct/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"code_of_conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li> <p>Using welcoming and inclusive language</p> </li> <li> <p>Being respectful of differing viewpoints and experiences</p> </li> <li> <p>Gracefully accepting constructive criticism</p> </li> <li> <p>Focusing on what is best for the community</p> </li> <li> <p>Showing empathy towards other community members</p> </li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li> <p>The use of sexualized language or imagery and unwelcome sexual attention or advances</p> </li> <li> <p>Trolling, insulting/derogatory comments, and personal or political attacks</p> </li> <li> <p>Public or private harassment</p> </li> <li> <p>Publishing others' private information, such as a physical or electronic address, without explicit permission</p> </li> <li> <p>Other conduct which could reasonably be considered inappropriate in a professional setting</p> </li> </ul>"},{"location":"code_of_conduct/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"code_of_conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"code_of_conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at erwan.schild@e-i.com. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.</p> <p>Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.</p>"},{"location":"code_of_conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at http://contributor-covenant.org/version/1/4</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p>"},{"location":"contributing/#environment-setup","title":"Environment setup","text":"<p>Nothing easier! Follow the instructions below.</p> <p>Note</p> <p>We STRONGLY recommend using a Linux distribution for Python development (Windows sometimes leads to obscure compatibility errors...)</p> <ol> <li> <p>Install <code>Git</code> to version and track our software changes.</p> <ul> <li> <p>On Windows, use the official installer: <code>Git-for-Windows</code>.</p> </li> <li> <p>On Linux, simply use your package manager.</p> </li> </ul> <p>Note</p> <p><code>Git-for-Windows</code> doesn't provide the command <code>make</code>. In following step, use <code>pdm</code> instead.</p> </li> <li> <p>Install <code>Python</code> as programming language for this projet.</p> <ul> <li> <p>On Windows, use the official installer: Python Releases for Windows.</p> </li> <li> <p>On Linux, simply use your package manager.</p> </li> </ul> <p>Note</p> <p>You can also use use <code>pyenv</code>.</p> <pre><code># install pyenv\ngit clone https://github.com/pyenv/pyenv ~/.pyenv\n\n# setup pyenv (you should also put these three lines in .bashrc or similar)\nexport PATH=\"${HOME}/.pyenv/bin:${PATH}\"\nexport PYENV_ROOT=\"${HOME}/.pyenv\"\neval \"$(pyenv init -)\"\n\n# install Python 3.8\npyenv install 3.8\n\n# make it available globally\npyenv global system 3.8\n</code></pre> </li> <li> <p>Fork and clone the repository:</p> <pre><code>git clone https://github.com/cognitivefactory/features-maximization-metric/\ncd features-maximization-metric\n</code></pre> </li> <li> <p>Install the dependencies of the projet with:</p> <pre><code>cd interactive-clustering\nmake setup # on Linux\npdm install # on Windows\n</code></pre> <p>Note</p> <p>If it fails for some reason (especially on Windows), you'll need to install <code>pipx</code> and <code>pdm</code> manually.</p> <p>You can install them with:</p> <pre><code>python3 -m pip install --user pipx\npipx install pdm\n</code></pre> <p>Now you can try running <code>make setup</code> again, or simply <code>pdm install</code>.</p> </li> </ol> <p>Your project is now ready and dependencies are installed.</p>"},{"location":"contributing/#available-template-tasks","title":"Available template tasks","text":"<p>This project uses duty to run tasks. A Makefile is also provided. To run a task, use <code>make TASK</code> on Linux and <code>pdm run duty TASK</code> on Windows.</p> <p>To show the available template task:</p> <pre><code>make help # on Linux\npdm run duty --list # on Windows\n</code></pre> <p>The Makefile will try to run certain tasks on multiple Python versions. If for some reason you don't want to run the task on multiple Python versions, you can do one of the following:</p> <ol> <li><code>export PYTHON_VERSIONS=</code>: this will run the task    with only the current Python version</li> <li>run the task directly with <code>pdm run duty TASK</code></li> </ol> <p>The Makefile detects if a virtual environment is activated, so <code>make</code>/<code>pdm</code> will work the same with the virtualenv activated or not.</p>"},{"location":"contributing/#development-journey","title":"Development journey","text":"<p>As usual:</p> <ol> <li>create a new branch: <code>git checkout -b feature-or-bugfix-name</code></li> <li>edit the code and/or the documentation</li> </ol> <p>If you updated the documentation or the project dependencies:</p> <ol> <li>run <code>make docs-regen</code></li> <li>run <code>make docs-serve</code>, go to http://localhost:8000 and check that everything looks good</li> </ol> <p>Before committing:</p> <ol> <li>run <code>make format</code> to auto-format the code</li> <li>run <code>make check</code> to check everything (fix any warning)</li> <li>run <code>make test</code> to run the tests (fix any issue)</li> <li>follow our commit message convention</li> </ol> <p>If you are unsure about how to fix or ignore a warning, just let the continuous integration fail, and we will help you during review.</p> <p>Don't bother updating the changelog, we will take care of this.</p>"},{"location":"contributing/#commit-message-convention","title":"Commit message convention","text":"<p>Commits messages must follow the Angular style:</p> <pre><code>&lt;type&gt;[(scope)]: Subject\n\n[Body]\n</code></pre> <p>Scope and body are optional. Type can be:</p> <ul> <li><code>build</code>: About packaging, building wheels, etc.</li> <li><code>chore</code>: About packaging or repo/files management.</li> <li><code>ci</code>: About Continuous Integration.</li> <li><code>docs</code>: About documentation.</li> <li><code>feat</code>: New feature.</li> <li><code>fix</code>: Bug fix.</li> <li><code>perf</code>: About performance.</li> <li><code>refactor</code>: Changes which are not features nor bug fixes.</li> <li><code>style</code>: A change in code style/format.</li> <li><code>tests</code>: About tests.</li> </ul> <p>Subject (and body) must be valid Markdown. If you write a body, please add issues references at the end:</p> <pre><code>Body.\n\nReferences: #10, #11.\nFixes #15.\n</code></pre>"},{"location":"contributing/#pull-requests-guidelines","title":"Pull requests guidelines","text":"<p>Link to any related issue in the Pull Request message.</p> <p>During review, we recommend using fixups:</p> <pre><code># SHA is the SHA of the commit you want to fix\ngit commit --fixup=SHA\n</code></pre> <p>Once all the changes are approved, you can squash your commits:</p> <pre><code>git rebase -i --autosquash master\n</code></pre> <p>And force-push:</p> <pre><code>git push -f\n</code></pre> <p>If this seems all too complicated, you can push or force-push each new commit, and we will squash them ourselves if needed, before merging.</p>"},{"location":"credits/","title":"Credits","text":"<p>These projects were used to build <code>cognitivefactory-features-maximization-metric</code>. Thank you!</p> <p><code>python</code> | <code>pdm</code> | <code>copier-pdm</code></p>"},{"location":"credits/#exec-0--runtime-dependencies","title":"Runtime dependencies","text":"Project Summary Version (accepted) Version (last resolved) License <code>joblib</code> Lightweight pipelining with Python functions <code>&gt;=1.1.1</code> <code>1.2.0</code> BSD <code>numpy</code> Fundamental package for array computing in Python <code>&gt;=1.22.2</code> <code>1.24.2</code> BSD-3-Clause <code>scikit-learn</code> A set of python modules for machine learning and data mining <code>&gt;=0.24.1</code> <code>1.2.1</code> new BSD <code>scipy</code> Fundamental algorithms for scientific computing in Python <code>&gt;=1.7.3</code> <code>1.9.3</code> BSD License <code>threadpoolctl</code> threadpoolctl <code>&gt;=2.0.0</code> <code>3.1.0</code> BSD-3-Clause"},{"location":"credits/#exec-0--development-dependencies","title":"Development dependencies","text":"Project Summary Version (accepted) Version (last resolved) License <code>ansimarkup</code> Produce colored terminal text with an xml-like markup <code>~=1.4</code> <code>1.5.0</code> Revised BSD License <code>astor</code> Read/rewrite/write Python ASTs <code>&gt;=0.8</code> <code>0.8.1</code> BSD-3-Clause <code>attrs</code> Classes Without Boilerplate <code>&gt;=19.2.0</code> <code>22.1.0</code> MIT <code>autoflake</code> Removes unused imports and unused variables <code>&gt;=1.4</code> <code>1.7.8</code> MIT <code>bandit</code> Security oriented static analyser for python code. <code>&gt;=1.7.3</code> <code>1.7.4</code> Apache-2.0 license <code>black</code> The uncompromising code formatter. <code>&gt;=21.10b0</code> <code>23.1.0</code> MIT <code>certifi</code> Python package for providing Mozilla's CA Bundle. <code>&gt;=2022.12.7</code> <code>2022.12.7</code> MPL-2.0 <code>charset-normalizer</code> The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet. <code>&lt;3,&gt;=2</code> <code>2.1.1</code> MIT <code>click</code> Composable command line interface toolkit <code>&gt;=8.0.0</code> <code>8.1.3</code> BSD-3-Clause <code>colorama</code> Cross-platform colored terminal text. <code>; platform_system == \"Windows\"</code> <code>0.4.6</code> BSD License <code>coverage</code> Code coverage measurement for Python <code>[toml]&gt;=5.2.1</code> <code>6.5.0</code> Apache 2.0 <code>darglint</code> A utility for ensuring Google-style docstrings stay up to date with the source code. <code>&gt;=1.8</code> <code>1.8.1</code> MIT <code>dparse</code> A parser for Python dependency files <code>&gt;=0.6.2</code> <code>0.6.2</code> MIT license <code>duty</code> A simple task runner. <code>&gt;=0.7</code> <code>0.7.0</code> Other/Proprietary License <code>exceptiongroup</code> Backport of PEP 654 (exception groups) <code>&gt;=1.0.0rc8; python_version &lt; \"3.11\"</code> <code>1.0.4</code> MIT License <code>execnet</code> execnet: rapid multi-Python deployment <code>&gt;=1.1</code> <code>1.9.0</code> MIT <code>failprint</code> Run a command, print its output only if it fails. <code>~=0.8</code> <code>0.8.0</code> Other/Proprietary License <code>flake8</code> the modular source code checker: pep8 pyflakes and co <code>&gt;=4.0</code> <code>5.0.4</code> MIT <code>flake8-bandit</code> Automated security testing with bandit and flake8. <code>&gt;=2.1</code> <code>4.1.1</code> MIT <code>flake8-black</code> flake8 plugin to call black as a code style validator <code>&gt;=0.2</code> <code>0.3.6</code> MIT <code>flake8-bugbear</code> A plugin for flake8 finding likely bugs and design problems in your program. Contains warnings that don't belong in pyflakes and pycodestyle. <code>&gt;=21.9</code> <code>23.2.13</code> MIT <code>flake8-builtins</code> Check for python builtins being used as variables or parameters. <code>&gt;=1.5</code> <code>2.1.0</code> GPL version 2 <code>flake8-comprehensions</code> A flake8 plugin to help you write better list/set/dict comprehensions. <code>&gt;=3.7</code> <code>3.10.1</code> MIT <code>flake8-docstrings</code> Extension for flake8 which uses pydocstyle to check docstrings <code>&gt;=1.6</code> <code>1.7.0</code> MIT <code>flake8-plugin-utils</code> The package provides base classes and utils for flake8 plugin writing <code>&lt;2.0.0,&gt;=1.3.2</code> <code>1.3.2</code> MIT <code>flake8-polyfill</code> Polyfill package for Flake8 plugins <code>&gt;=1.0.2</code> <code>1.0.2</code> MIT <code>flake8-pytest-style</code> A flake8 plugin checking common style issues or inconsistencies with pytest-based tests. <code>&gt;=1.5</code> <code>1.7.2</code> MIT <code>flake8-string-format</code> string format checker, plugin for flake8 <code>&gt;=0.3</code> <code>0.3.0</code> MIT License <code>flake8-tidy-imports</code> A flake8 plugin that helps you write tidier imports. <code>&gt;=4.5</code> <code>4.8.0</code> MIT <code>flake8-variables-names</code> A flake8 extension that helps to make more readable variables names <code>&gt;=0.0</code> <code>0.0.5</code> MIT <code>ghp-import</code> Copy your docs directly to the gh-pages branch. <code>&gt;=1.0</code> <code>2.1.0</code> Apache Software License <code>git-changelog</code> Automatic Changelog generator using Jinja2 templates. <code>&gt;=0.4,&lt;1.0</code> <code>0.6.0</code> ISC <code>gitdb</code> Git Object Database <code>&lt;5,&gt;=4.0.1</code> <code>4.0.10</code> BSD License <code>gitpython</code> GitPython is a python library used to interact with Git repositories <code>&gt;=3.1.30</code> <code>3.1.30</code> BSD <code>griffe</code> Signatures for entire Python programs. Extract the structure, the frame, the skeleton of your project, to generate API documentation or find breaking changes in your API. <code>&gt;=0.24</code> <code>0.24.1</code> ISC <code>idna</code> Internationalized Domain Names in Applications (IDNA) <code>&lt;4,&gt;=2.5</code> <code>3.4</code> BSD License <code>importlib-metadata</code> Read metadata from Python packages <code>&gt;=4.3; python_version &lt; \"3.10\"</code> <code>4.13.0</code> Apache Software License <code>iniconfig</code> iniconfig: brain-dead simple config-ini parsing <code>1.1.1</code> MIT License <code>isort</code> A Python utility / library to sort Python imports. <code>&gt;=5.10</code> <code>5.12.0</code> MIT <code>jinja2</code> A very fast and expressive template engine. <code>&lt;4,&gt;=2.11</code> <code>3.1.2</code> BSD-3-Clause <code>markdown</code> Python implementation of Markdown. <code>&lt;4.0.0,&gt;=3.3.3</code> <code>3.3.7</code> BSD License <code>markdown-callouts</code> Markdown extension: a classier syntax for admonitions <code>&gt;=0.2</code> <code>0.3.0</code> MIT <code>markdown-exec</code> Utilities to execute code blocks in Markdown files. <code>&gt;=0.5</code> <code>1.2.0</code> ISC <code>markupsafe</code> Safely add untrusted strings to HTML/XML markup. <code>&gt;=2.0</code> <code>2.1.1</code> BSD-3-Clause <code>mccabe</code> McCabe checker, plugin for flake8 <code>&lt;0.8.0,&gt;=0.7.0</code> <code>0.7.0</code> Expat license <code>mergedeep</code> A deep merge function for \ud83d\udc0d. <code>&gt;=1.3.4</code> <code>1.3.4</code> MIT License <code>mkdocs</code> Project documentation with Markdown. <code>&gt;=1.3</code> <code>1.4.2</code> BSD License <code>mkdocs-coverage</code> MkDocs plugin to integrate your coverage HTML report into your site. <code>&gt;=0.2</code> <code>0.2.6</code> ISC <code>mkdocs-gen-files</code> MkDocs plugin to programmatically generate documentation pages during the build <code>&gt;=0.3</code> <code>0.4.0</code> MIT <code>mkdocs-literate-nav</code> MkDocs plugin to specify the navigation in Markdown instead of YAML <code>&gt;=0.4</code> <code>0.6.0</code> MIT License <code>mkdocs-material</code> Documentation that simply works <code>&gt;=7.3</code> <code>9.0.12</code> MIT License <code>mkdocs-material-extensions</code> Extension pack for Python Markdown and MkDocs Material. <code>&gt;=1.1</code> <code>1.1.1</code> MIT License <code>mkdocs-section-index</code> MkDocs plugin to allow clickable sections that lead to an index page <code>&gt;=0.3</code> <code>0.3.5</code> MIT License <code>mkdocstrings</code> Automatic documentation from sources, for MkDocs. <code>[python]&gt;=0.18</code> <code>0.20.0</code> ISC <code>mkdocstrings-python</code> A Python handler for mkdocstrings. <code>&gt;=0.5.2</code> <code>0.8.2</code> ISC <code>mypy</code> Optional static typing for Python <code>&gt;=0.910</code> <code>1.0.0</code> MIT License <code>mypy-extensions</code> Experimental type system extensions for programs checked with the mypy typechecker. <code>&gt;=0.4.3</code> <code>0.4.3</code> MIT License <code>packaging</code> Core utilities for Python packages <code>&gt;=22.0</code> <code>23.0</code> BSD License <code>pathspec</code> Utility library for gitignore style pattern matching of file paths. <code>&gt;=0.9.0</code> <code>0.10.2</code> MPL 2.0 <code>pbr</code> Python Build Reasonableness <code>!=2.1.0,&gt;=2.0.0</code> <code>5.11.0</code> Apache Software License <code>pep8-naming</code> Check PEP-8 naming conventions, plugin for flake8 <code>&gt;=0.12</code> <code>0.13.3</code> Expat license <code>platformdirs</code> A small Python package for determining appropriate platform-specific dirs, e.g. a \"user data dir\". <code>&gt;=2</code> <code>2.5.4</code> MIT License <code>pluggy</code> plugin and hook calling mechanisms for python <code>&lt;2.0,&gt;=0.12</code> <code>1.0.0</code> MIT <code>ptyprocess</code> Run a subprocess in a pseudo terminal <code>~=0.6; sys_platform != \"win32\"</code> <code>0.7.0</code> ? <code>pycodestyle</code> Python style guide checker <code>&lt;2.10.0,&gt;=2.9.0</code> <code>2.9.1</code> Expat license <code>pydocstyle</code> Python docstring style checker <code>&gt;=2.1</code> <code>6.1.1</code> MIT <code>pyflakes</code> passive checker of Python programs <code>&lt;3,&gt;=1.1.0</code> <code>2.5.0</code> MIT <code>pygments</code> Pygments is a syntax highlighting package written in Python. <code>&gt;=2.14</code> <code>2.14.0</code> BSD-2-Clause <code>pymdown-extensions</code> Extension pack for Python Markdown. <code>&gt;=9</code> <code>9.9.2</code> MIT License <code>pytest</code> pytest: simple powerful testing with Python <code>&gt;=6.2</code> <code>7.2.1</code> MIT <code>pytest-cov</code> Pytest plugin for measuring coverage. <code>&gt;=3.0</code> <code>4.0.0</code> MIT <code>pytest-randomly</code> Pytest plugin to randomly order tests and control random.seed. <code>&gt;=3.10</code> <code>3.12.0</code> MIT <code>pytest-xdist</code> pytest xdist plugin for distributed testing, most importantly across multiple CPUs <code>&gt;=2.4</code> <code>3.2.0</code> MIT <code>python-dateutil</code> Extensions to the standard Python datetime module <code>&gt;=2.8.1</code> <code>2.8.2</code> Dual License <code>pyyaml</code> YAML parser and emitter for Python <code>&gt;=5.1</code> <code>6.0</code> MIT <code>pyyaml-env-tag</code> A custom YAML tag for referencing environment variables in YAML files. <code>&gt;=0.1</code> <code>0.1</code> MIT License <code>regex</code> Alternative regular expression module, to replace re. <code>&gt;=2022.4.24</code> <code>2022.10.31</code> Apache Software License <code>requests</code> Python HTTP for Humans. <code>&gt;=2.26</code> <code>2.28.1</code> Apache 2.0 <code>ruamel.yaml</code> ruamel.yaml is a YAML parser/emitter that supports roundtrip preservation of comments, seq/map flow style, and map key order <code>&gt;=0.17.21</code> <code>0.17.21</code> MIT license <code>ruamel.yaml.clib</code> C version of reader, parser and emitter for ruamel.yaml derived from libyaml <code>&gt;=0.2.6; platform_python_implementation == \"CPython\" and python_version &lt; \"3.11\"</code> <code>0.2.7</code> MIT <code>safety</code> Checks installed dependencies for known vulnerabilities and licenses. <code>&gt;=2</code> <code>2.3.4</code> MIT license <code>semver</code> Python helper for Semantic Versioning (http://semver.org/) <code>~=2.13</code> <code>2.13.0</code> BSD <code>setuptools</code> Easily download, build, install, upgrade, and uninstall Python packages <code>&gt;=19.3</code> <code>65.6.3</code> MIT License <code>six</code> Python 2 and 3 compatibility utilities <code>&gt;=1.5</code> <code>1.16.0</code> MIT <code>smmap</code> A pure Python implementation of a sliding window memory map manager <code>&lt;6,&gt;=3.0.1</code> <code>5.0.0</code> BSD <code>snowballstemmer</code> This package provides 29 stemmers for 28 languages generated from Snowball algorithms. <code>2.2.0</code> BSD-3-Clause <code>stevedore</code> Manage dynamic plugins for Python applications <code>&gt;=1.20.0</code> <code>3.5.2</code> Apache Software License <code>toml</code> Python Library for Tom's Obvious, Minimal Language <code>&gt;=0.10</code> <code>0.10.2</code> MIT <code>tomli</code> A lil' TOML parser <code>&gt;=2.0.1; python_version &lt; \"3.11\"</code> <code>2.0.1</code> MIT License <code>types-markdown</code> Typing stubs for Markdown <code>&gt;=3.3</code> <code>3.4.2.4</code> Apache-2.0 license <code>types-toml</code> Typing stubs for toml <code>&gt;=0.10</code> <code>0.10.8.4</code> Apache-2.0 license <code>typing-extensions</code> Backported and Experimental Type Hints for Python 3.7+ <code>&gt;=3.10.0.0; python_version &lt; \"3.10\"</code> <code>4.4.0</code> Python Software Foundation License <code>urllib3</code> HTTP library with thread-safe connection pooling, file post, and more. <code>&lt;1.27,&gt;=1.21.1</code> <code>1.26.13</code> MIT <code>watchdog</code> Filesystem events monitoring <code>&gt;=2.0</code> <code>2.1.9</code> Apache License 2.0 <code>wps-light</code> The strictest and most opinionated python linter ever (lighter fork). <code>&gt;=0.15</code> <code>0.16.1</code> MIT <code>zipp</code> Backport of pathlib-compatible object wrapper for zip files <code>&gt;=0.5</code> <code>3.10.0</code> MIT License"},{"location":"license/","title":"CeCILL-C FREE SOFTWARE LICENSE AGREEMENT","text":""},{"location":"license/#notice","title":"Notice","text":"<p>This Agreement is a Free Software license agreement that is the result of discussions between its authors in order to ensure compliance with the two main principles guiding its drafting:</p> <ul> <li> <p>firstly, compliance with the principles governing the distribution of Free Software: access to source code, broad rights granted to users,</p> </li> <li> <p>secondly, the election of a governing law, French law, with which it is conformant, both as regards the law of torts and intellectual property law, and the protection that it offers to both authors and holders of the economic rights over software.</p> </li> </ul> <p>The authors of the CeCILL-C license are:</p> <ul> <li> <p>Commissariat \u00e0 l'Energie Atomique - CEA, a public scientific, technical and industrial research establishment, having its principal place of business at 25 rue Leblanc, immeuble Le Ponant D, 75015 Paris, France.</p> </li> <li> <p>Centre National de la Recherche Scientifique - CNRS, a public scientific and technological establishment, having its principal place of business at 3 rue Michel-Ange, 75794 Paris cedex 16, France.</p> </li> <li> <p>Institut National de Recherche en Informatique et en Automatique - INRIA, a public scientific and technological establishment, having its principal place of business at Domaine de Voluceau, Rocquencourt, BP 105, 78153 Le Chesnay cedex, France.</p> </li> </ul> <p> CeCILL stands for Ce(a) C(nrs) I(nria) L(ogiciel) L(ibre)</p>"},{"location":"license/#preamble","title":"Preamble","text":"<p>The purpose of this Free Software license agreement is to grant users the right to modify and re-use the software governed by this license.</p> <p>The exercising of this right is conditional upon the obligation to make available to the community the modifications made to the source code of the software so as to contribute to its evolution.</p> <p>In consideration of access to the source code and the rights to copy, modify and redistribute granted by the license, users are provided only with a limited warranty and the software's author, the holder of the economic rights, and the successive licensors only have limited liability.</p> <p>In this respect, the risks associated with loading, using, modifying and/or developing or reproducing the software by the user are brought to the user's attention, given its Free Software status, which may make it complicated to use, with the result that its use is reserved for developers and experienced professionals having in-depth computer knowledge. Users are therefore encouraged to load and test the suitability of the software as regards their requirements in conditions enabling the security of their systems and/or data to be ensured and, more generally, to use and operate it in the same conditions of security. This Agreement may be freely reproduced and published, provided it is not altered, and that no provisions are either added or removed herefrom.</p> <p>This Agreement may apply to any or all software for which the holder of the economic rights decides to submit the use thereof to its provisions.</p>"},{"location":"license/#article-1-definitions","title":"Article 1 - DEFINITIONS","text":"<p>For the purpose of this Agreement, when the following expressions commence with a capital letter, they shall have the following meaning:</p> <p>Agreement: means this license agreement, and its possible subsequent versions and annexes.</p> <p>Software: means the software in its Object Code and/or Source Code form and, where applicable, its documentation, \"as is\" when the Licensee accepts the Agreement.</p> <p>Initial Software: means the Software in its Source Code and possibly its Object Code form and, where applicable, its documentation, \"as is\" when it is first distributed under the terms and conditions of the Agreement.</p> <p>Modified Software: means the Software modified by at least one Integrated Contribution.</p> <p>Source Code: means all the Software's instructions and program lines to which access is required so as to modify the Software.</p> <p>Object Code: means the binary files originating from the compilation of the Source Code.</p> <p>Holder: means the holder(s) of the economic rights over the Initial Software.</p> <p>Licensee: means the Software user(s) having accepted the Agreement.</p> <p>Contributor: means a Licensee having made at least one Integrated Contribution.</p> <p>Licensor: means the Holder, or any other individual or legal entity, who distributes the Software under the Agreement.</p> <p>Integrated Contribution: means any or all modifications, corrections, translations, adaptations and/or new functions integrated into the Source Code by any or all Contributors.</p> <p>Related Module: means a set of sources files including their documentation that, without modification to the Source Code, enables supplementary functions or services in addition to those offered by the Software.</p> <p>Derivative Software: means any combination of the Software, modified or not, and of a Related Module.</p> <p>Parties: mean both the Licensee and the Licensor.</p> <p>These expressions may be used both in singular and plural form.</p>"},{"location":"license/#article-2-purpose","title":"Article 2 - PURPOSE","text":"<p>The purpose of the Agreement is the grant by the Licensor to the Licensee of a non-exclusive, transferable and worldwide license for the Software as set forth in Article 5 hereinafter for the whole term of the protection granted by the rights over said Software.</p>"},{"location":"license/#article-3-acceptance","title":"Article 3 - ACCEPTANCE","text":"<p> 3.1 The Licensee shall be deemed as having accepted the terms and conditions of this Agreement upon the occurrence of the first of the following events:</p> <ul> <li> <p>(i) loading the Software by any or all means, notably, by downloading from a remote server, or by loading from a physical medium;</p> </li> <li> <p>(ii) the first time the Licensee exercises any of the rights granted hereunder.</p> </li> </ul> <p> 3.2 One copy of the Agreement, containing a notice relating to the characteristics of the Software, to the limited warranty, and to the fact that its use is restricted to experienced users has been provided to the Licensee prior to its acceptance as set forth in Article 3.1 hereinabove, and the Licensee hereby acknowledges that it has read and understood it.</p>"},{"location":"license/#article-4-effective-date-and-term","title":"Article 4 - EFFECTIVE DATE AND TERM","text":""},{"location":"license/#41-effective-date","title":"4.1 EFFECTIVE DATE","text":"<p>The Agreement shall become effective on the date when it is accepted by the Licensee as set forth in Article 3.1.</p>"},{"location":"license/#42-term","title":"4.2 TERM","text":"<p>The Agreement shall remain in force for the entire legal term of protection of the economic rights over the Software.</p>"},{"location":"license/#article-5-scope-of-rights-granted","title":"Article 5 - SCOPE OF RIGHTS GRANTED","text":"<p>The Licensor hereby grants to the Licensee, who accepts, the following rights over the Software for any or all use, and for the term of the Agreement, on the basis of the terms and conditions set forth hereinafter.</p> <p>Besides, if the Licensor owns or comes to own one or more patents protecting all or part of the functions of the Software or of its components, the Licensor undertakes not to enforce the rights granted by these patents against successive Licensees using, exploiting or modifying the Software. If these patents are transferred, the Licensor undertakes to have the transferees subscribe to the obligations set forth in this paragraph.</p>"},{"location":"license/#51-right-of-use","title":"5.1 RIGHT OF USE","text":"<p>The Licensee is authorized to use the Software, without any limitation as to its fields of application, with it being hereinafter specified that this comprises:</p> <ol> <li> <p>permanent or temporary reproduction of all or part of the Software by any or all means and in any or all form.</p> </li> <li> <p>loading, displaying, running, or storing the Software on any or all medium.</p> </li> <li> <p>entitlement to observe, study or test its operation so as to determine the ideas and principles behind any or all constituent elements of said Software. This shall apply when the Licensee carries out any or all loading, displaying, running, transmission or storage operation as regards the Software, that it is entitled to carry out hereunder.</p> </li> </ol>"},{"location":"license/#52-right-of-modification","title":"5.2 RIGHT OF MODIFICATION","text":"<p>The right of modification includes the right to translate, adapt, arrange, or make any or all modifications to the Software, and the right to reproduce the resulting software. It includes, in particular, the right to create a Derivative Software.</p> <p>The Licensee is authorized to make any or all modification to the Software provided that it includes an explicit notice that it is the author of said modification and indicates the date of the creation thereof.</p>"},{"location":"license/#53-right-of-distribution","title":"5.3 RIGHT OF DISTRIBUTION","text":"<p>In particular, the right of distribution includes the right to publish, transmit and communicate the Software to the general public on any or all medium, and by any or all means, and the right to market, either in consideration of a fee, or free of charge, one or more copies of the Software by any means.</p> <p>The Licensee is further authorized to distribute copies of the modified or unmodified Software to third parties according to the terms and conditions set forth hereinafter.</p>"},{"location":"license/#531-distribution-of-software-without-modification","title":"5.3.1 DISTRIBUTION OF SOFTWARE WITHOUT MODIFICATION","text":"<p>The Licensee is authorized to distribute true copies of the Software in Source Code or Object Code form, provided that said distribution complies with all the provisions of the Agreement and is accompanied by:</p> <ol> <li> <p>a copy of the Agreement,</p> </li> <li> <p>a notice relating to the limitation of both the Licensor's warranty and liability as set forth in Article 8 and Article 9,</p> </li> </ol> <p>and that, in the event that only the Object Code of the Software is redistributed, the Licensee allows effective access to the full Source Code of the Software at a minimum during the entire period of its distribution of the Software, it being understood that the additional cost of acquiring the Source Code shall not exceed the cost of transferring the data.</p>"},{"location":"license/#532-distribution-of-modified-software","title":"5.3.2 DISTRIBUTION OF MODIFIED SOFTWARE","text":"<p>When the Licensee makes an Integrated Contribution to the Software, the terms and conditions for the distribution of the resulting Modified Software become subject to all the provisions of this Agreement.</p> <p>The Licensee is authorized to distribute the Modified Software, in source code or object code form, provided that said distribution complies with all the provisions of the Agreement and is accompanied by:</p> <ol> <li> <p>a copy of the Agreement,</p> </li> <li> <p>a notice relating to the limitation of both the Licensor's warranty and liability as set forth in Article 8 and Article 9,</p> </li> </ol> <p>and that, in the event that only the object code of the Modified Software is redistributed, the Licensee allows effective access to the full source code of the Modified Software at a minimum during the entire period of its distribution of the Modified Software, it being understood that the additional cost of acquiring the source code shall not exceed the cost of transferring the data.</p>"},{"location":"license/#533-distribution-of-derivative-software","title":"5.3.3 DISTRIBUTION OF DERIVATIVE SOFTWARE","text":"<p>When the Licensee creates Derivative Software, this Derivative Software may be distributed under a license agreement other than this Agreement, subject to compliance with the requirement to include a notice concerning the rights over the Software as defined in Article 6.4. In the event the creation of the Derivative Software required modification of the Source Code, the Licensee undertakes that:</p> <ol> <li> <p>the resulting Modified Software will be governed by this Agreement,</p> </li> <li> <p>the Integrated Contributions in the resulting Modified Software will be clearly identified and documented,</p> </li> <li> <p>the Licensee will allow effective access to the source code of the Modified Software, at a minimum during the entire period of distribution of the Derivative Software, such that such modifications may be carried over in a subsequent version of the Software; it being understood that the additional cost of purchasing the source code of the Modified Software shall not exceed the cost of transferring the data.</p> </li> </ol>"},{"location":"license/#534-compatibility-with-the-cecill-license","title":"5.3.4 COMPATIBILITY WITH THE CeCILL LICENSE","text":"<p>When a Modified Software contains an Integrated Contribution subject to the CeCILL license agreement, or when a Derivative Software contains a Related Module subject to the CeCILL license agreement, the provisions set forth in the third item of Article 6.4 are optional.</p>"},{"location":"license/#article-6-intellectual-property","title":"Article 6 - INTELLECTUAL PROPERTY","text":""},{"location":"license/#61-over-the-initial-software","title":"6.1 OVER THE INITIAL SOFTWARE","text":"<p>The Holder owns the economic rights over the Initial Software. Any or all use of the Initial Software is subject to compliance with the terms and conditions under which the Holder has elected to distribute its work and no one shall be entitled to modify the terms and conditions for the distribution of said Initial Software.</p> <p>The Holder undertakes that the Initial Software will remain ruled at least by this Agreement, for the duration set forth in Article 4.2.</p>"},{"location":"license/#62-over-the-integrated-contributions","title":"6.2 OVER THE INTEGRATED CONTRIBUTIONS","text":"<p>The Licensee who develops an Integrated Contribution is the owner of the intellectual property rights over this Contribution as defined by applicable law.</p>"},{"location":"license/#63-over-the-related-modules","title":"6.3 OVER THE RELATED MODULES","text":"<p>The Licensee who develops a Related Module is the owner of the intellectual property rights over this Related Module as defined by applicable law and is free to choose the type of agreement that shall govern its distribution under the conditions defined in Article 5.3.3.</p>"},{"location":"license/#64-notice-of-rights","title":"6.4 NOTICE OF RIGHTS","text":"<p>The Licensee expressly undertakes:</p> <ol> <li> <p>not to remove, or modify, in any manner, the intellectual property notices attached to the Software;</p> </li> <li> <p>to reproduce said notices, in an identical manner, in the copies of the Software modified or not;</p> </li> <li> <p>to ensure that use of the Software, its intellectual property notices and the fact that it is governed by the Agreement is indicated in a text that is easily accessible, specifically from the interface of any Derivative Software.</p> </li> </ol> <p>The Licensee undertakes not to directly or indirectly infringe the intellectual property rights of the Holder and/or Contributors on the Software and to take, where applicable, vis-\u00e0-vis its staff, any and all measures required to ensure respect of said intellectual property rights of the Holder and/or Contributors.</p>"},{"location":"license/#article-7-related-services","title":"Article 7 - RELATED SERVICES","text":"<p> 7.1 Under no circumstances shall the Agreement oblige the Licensor to provide technical assistance or maintenance services for the Software.</p> <p>However, the Licensor is entitled to offer this type of services. The terms and conditions of such technical assistance, and/or such maintenance, shall be set forth in a separate instrument. Only the Licensor offering said maintenance and/or technical assistance services shall incur liability therefor.</p> <p> 7.2 Similarly, any Licensor is entitled to offer to its licensees, under its sole responsibility, a warranty, that shall only be binding upon itself, for the redistribution of the Software and/or the Modified Software, under terms and conditions that it is free to decide. Said warranty, and the financial terms and conditions of its application, shall be subject of a separate instrument executed between the Licensor and the Licensee.</p>"},{"location":"license/#article-8-liability","title":"Article 8 - LIABILITY","text":"<p> 8.1 Subject to the provisions of Article 8.2, the Licensee shall be entitled to claim compensation for any direct loss it may have suffered from the Software as a result of a fault on the part of the relevant Licensor, subject to providing evidence thereof.</p> <p> 8.2 The Licensor's liability is limited to the commitments made under this Agreement and shall not be incurred as a result of in particular:</p> <ul> <li> <p>(i) loss due the Licensee's total or partial failure to fulfill its obligations,</p> </li> <li> <p>(ii) direct or consequential loss that is suffered by the Licensee due to the use or performance of the Software, and</p> </li> <li> <p>(iii) more generally, any consequential loss.</p> </li> </ul> <p>In particular the Parties expressly agree that any or all pecuniary or business loss (i.e. loss of data, loss of profits, operating loss, loss of customers or orders, opportunity cost, any disturbance to business activities) or any or all legal proceedings instituted against the Licensee by a third party, shall constitute consequential loss and shall not provide entitlement to any or all compensation from the Licensor.</p>"},{"location":"license/#article-9-warranty","title":"Article 9 - WARRANTY","text":"<p> 9.1 The Licensee acknowledges that the scientific and technical state-of-the-art when the Software was distributed did not enable all possible uses to be tested and verified, nor for the presence of possible defects to be detected. In this respect, the Licensee's attention has been drawn to the risks associated with loading, using, modifying and/or developing and reproducing the Software which are reserved for experienced users.</p> <p>The Licensee shall be responsible for verifying, by any or all means, the suitability of the product for its requirements, its good working order, and for ensuring that it shall not cause damage to either persons or properties.</p> <p> 9.2 The Licensor hereby represents, in good faith, that it is entitled to grant all the rights over the Software (including in particular the rights set forth in Article 5).</p> <p> 9.3 The Licensee acknowledges that the Software is supplied \"as is\" by the Licensor without any other express or tacit warranty, other than that provided for in Article 9.2 and, in particular, without any warranty as to its commercial value, its secured, safe, innovative or relevant nature.</p> <p>Specifically, the Licensor does not warrant that the Software is free from any error, that it will operate without interruption, that it will be compatible with the Licensee's own equipment and software configuration, nor that it will meet the Licensee's requirements.</p> <p> 9.4 The Licensor does not either expressly or tacitly warrant that the Software does not infringe any third party intellectual property right relating to a patent, software or any other property right. Therefore, the Licensor disclaims any and all liability towards the Licensee arising out of any or all proceedings for infringement that may be instituted in respect of the use, modification and redistribution of the Software. Nevertheless, should such proceedings be instituted against the Licensee, the Licensor shall provide it with technical and legal assistance for its defense. Such technical and legal assistance shall be decided on a case-by-case basis between the relevant Licensor and the Licensee pursuant to a memorandum of understanding. The Licensor disclaims any and all liability as regards the Licensee's use of the name of the Software. No warranty is given as regards the existence of prior rights over the name of the Software or as regards the existence of a trademark.</p>"},{"location":"license/#article-10-termination","title":"Article 10 - TERMINATION","text":"<p> 10.1 In the event of a breach by the Licensee of its obligations hereunder, the Licensor may automatically terminate this Agreement thirty (30) days after notice has been sent to the Licensee and has remained ineffective.</p> <p> 10.2 A Licensee whose Agreement is terminated shall no longer be authorized to use, modify or distribute the Software. However, any licenses that it may have granted prior to termination of the Agreement shall remain valid subject to their having been granted in compliance with the terms and conditions hereof.</p>"},{"location":"license/#article-11-miscellaneous","title":"Article 11 - MISCELLANEOUS","text":"<p> 11.1 EXCUSABLE EVENTS Neither Party shall be liable for any or all delay, or failure to perform the Agreement, that may be attributable to an event of force majeure, an act of God or an outside cause, such as defective functioning or interruptions of the electricity or telecommunications networks, network paralysis following a virus attack, intervention by government authorities, natural disasters, water damage, earthquakes, fire, explosions, strikes and labor unrest, war, etc.</p> <p> 11.2 Any failure by either Party, on one or more occasions, to invoke one or more of the provisions hereof, shall under no circumstances be interpreted as being a waiver by the interested Party of its right to invoke said provision(s) subsequently.</p> <p> 11.3 The Agreement cancels and replaces any or all previous agreements, whether written or oral, between the Parties and having the same purpose, and constitutes the entirety of the agreement between said Parties concerning said purpose. No supplement or modification to the terms and conditions hereof shall be effective as between the Parties unless it is made in writing and signed by their duly authorized representatives.</p> <p> 11.4 In the event that one or more of the provisions hereof were to conflict with a current or future applicable act or legislative text, said act or legislative text shall prevail, and the Parties shall make the necessary amendments so as to comply with said act or legislative text. All other provisions shall remain effective. Similarly, invalidity of a provision of the Agreement, for any reason whatsoever, shall not cause the Agreement as a whole to be invalid.</p> <p> 11.5 LANGUAGE The Agreement is drafted in both French and English and both versions are deemed authentic.</p>"},{"location":"license/#article-12-new-versions-of-the-agreement","title":"Article 12 - NEW VERSIONS OF THE AGREEMENT","text":"<p> 12.1 Any person is authorized to duplicate and distribute copies of this Agreement.</p> <p> 12.2 So as to ensure coherence, the wording of this Agreement is protected and may only be modified by the authors of the License, who reserve the right to periodically publish updates or new versions of the Agreement, each with a separate number. These subsequent versions may address new issues encountered by Free Software.</p> <p> 12.3 Any Software distributed under a given version of the Agreement may only be subsequently distributed under the same version of the Agreement or a subsequent version.</p>"},{"location":"license/#article-13-governing-law-and-jurisdiction","title":"Article 13 - GOVERNING LAW AND JURISDICTION","text":"<p> 13.1 The Agreement is governed by French law. The Parties agree to endeavor to seek an amicable solution to any disagreements or disputes that may arise during the performance of the Agreement.</p> <p> 13.2 Failing an amicable solution within two (2) months as from their occurrence, and unless emergency proceedings are necessary, the disagreements or disputes shall be referred to the Paris Courts having jurisdiction, by the more diligent Party.</p> <p>Version 1.0 dated 2006-09-05.</p>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#basic-usecase-what-are-the-physical-characteristics-that-most-distinguish-men-from-women","title":"Basic usecase: \"What are the physical characteristics that most distinguish men from women?\"","text":"<ol> <li> <p>Load Python dependencies: <pre><code>###\n### Python dependencies.\n###\n\nfrom cognitivefactory.feature_maximization_metric.fmc import FeaturesMaximizationMetric\nfrom scipy.sparse import csr_matrix\nfrom typing import List\n</code></pre></p> </li> <li> <p>Define problem data: <pre><code>###\n### Data.\n###\n\n# Define people characteristics that will be studied.\ncharacteristics_studied: List[str] = [\n    \"Shoes size\",\n    \"Hair size\",\n    \"Nose size\",\n]\n\n# Get people characteristics.\npeople_characteristics: csr_matrix = csr_matrix(\n    [\n        [9, 5, 5],\n        [9, 10, 5],\n        [9, 20, 6],\n        [5, 15, 5],\n        [6, 25, 6],\n        [5, 25, 5],\n    ]\n)\n\n# Get people genders.\npeople_genders: List[str] = [\n    \"Man\",\n    \"Man\",\n    \"Man\",\n    \"Woman\",\n    \"Woman\",\n    \"Woman\",\n]\n</code></pre></p> </li> <li> <p>Modelize the problem: <pre><code>###\n### Feature Maximization Metrics.\n###\n\n# Main computation.\nfmc_computer: FeaturesMaximizationMetric = FeaturesMaximizationMetric(\n    data_vectors=people_characteristics,\n    data_classes=people_genders,\n    list_of_possible_features=characteristics_studied,\n    amplification_factor=1,\n)\n</code></pre></p> </li> <li> <p>Determine relevant characteristics: <pre><code>###\n### Analysis 1: Delete characteristics that aren't relevant.\n###\n\nprint(\n    \"\\n\",\n    \"1. Which characteristic seems not relevant to distinguish men from women ?\",\n)\nfor characteristic in characteristics_studied:\n    if not fmc_computer.features_selection[characteristic]:\n        print(\n            \"    - '{0}' seems not relevant.\".format(characteristic)\n        )\n</code></pre> <pre><code>1. Which characteristic seems not relevant to distinguish men from women ?\n    - 'Nose size' seems not relevant.\n</code></pre></p> </li> <li> <p>Describe gender by relevant characteristics.: <pre><code>###\n### Analysis 2: Describe gender by relevant characteristics.\n###\n\nprint(\n    \"\\n\",\n    \"2. According to remaining characteristics:\",\n)\nfor gender in sorted(set(people_genders)):\n    print(\n        \"    - Which characteristic seems important to recognize a '{0}' ?\".format(gender)\n    )\n\n    for characteristic in fmc_computer.get_most_active_features_by_a_classe(\n        classe=gender,\n    ):\n        print(\n            \"        - '{0}' seems important (fmeasure of '{1:.2f}', contrast of '{2:.2f}').\".format(\n                characteristic,\n                fmc_computer.features_fmeasure[characteristic][gender],\n                fmc_computer.features_contrast[characteristic][gender],\n            )\n        )\n</code></pre> <pre><code>2. According to remaining characteristics:\n    - Which characteristic seems important to recognize a 'Man' ?\n        - 'Shoes size' seems important (fmeasure of '0.45', contrast of '1.32').\n    - Which characteristic seems important to recognize a 'Woman' ?\n        - 'Hair size' seems important (fmeasure of '0.66', contrast of '1.25').\n</code></pre></p> </li> </ol>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>cognitivefactory<ul> <li>features_maximization_metric<ul> <li>fmc</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/cognitivefactory/features_maximization_metric/","title":"features_maximization_metric","text":"<p>cognitivefactory-features-maximization-metric package.</p> <p>Implementation of Features Maximization Metric, an unbiased metric aimed at estimate the quality of an unsupervised classification.</p>"},{"location":"reference/cognitivefactory/features_maximization_metric/fmc/","title":"fmc","text":"<ul> <li>Name:         cognitivefactory.features_maximization_metric.fmc</li> <li>Description:  Implementation of Features Maximization Metrics.</li> <li>Author:       Erwan SCHILD</li> <li>Created:      23/11/2022</li> <li>Licence:      CeCILL-C License v1.0 (https://cecill.info/licences.fr.html)</li> </ul>"},{"location":"reference/cognitivefactory/features_maximization_metric/fmc/#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric","title":"<code>FeaturesMaximizationMetric</code>","text":"<p>This class implements the Features Maximization Metric. It's a dataset modelization based on vectors features and data labels: for each couple <code>(feature, classe)</code>, it gives a score (called F-Measure) that describe the power of identification and distinction of the feature for this classe.</p> This metric is computed by applying the following steps <ol> <li> <p>Compute the Features F-Measure metric (based on Features Recall and Features Predominance metrics).</p> <p>(a) The Features Recall <code>FR[f][c]</code> for a given class <code>c</code> and a given feature <code>f</code> is the ratio between the sum of the vectors weights of the feature <code>f</code> for data in class <code>c</code> and the sum of all vectors weights of feature <code>f</code> for all data. It answers the question: \"Can the feature <code>f</code> distinguish the class <code>c</code> from other classes <code>c'</code> ?\"</p> <p>(b) The Features Predominance <code>FP[f][c]</code> for a given class <code>c</code> and a given feature <code>f</code> is the ratio between the sum of the vectors weights of the feature <code>f</code> for data in class <code>c</code> and the sum of all vectors weights of all feature <code>f'</code> for data in class <code>c</code>. It answers the question: \"Can the feature <code>f</code> better identify the class <code>c</code> than the other features <code>f'</code> ?\"</p> <p>(c) The Features F-Measure <code>FM[f][c]</code> for a given class <code>c</code> and a given feature <code>f</code> is the harmonic mean of the Features Recall (a) and the Features Predominance (c). It answers the question: \"How much information does the feature <code>f</code> contain about the class <code>c</code> ?\"</p> </li> <li> <p>Compute the Features Selection (based on F-Measure Overall Average comparison).</p> <p>(d) The F-Measure Overall Average is the average of Features F-Measure (c) for all classes <code>c</code> and for all features <code>f</code>. It answers the question: \"What are the mean of information contained by features in all classes ?\"</p> <p>(e) A feature <code>f</code> is Selected if and only if it exist at least one class <code>c</code> for which the Features F-Measure (c) <code>FM[f][c]</code> is bigger than the F-Measure Overall Average (d). It answers the question: \"What are the features which contain more information than the mean of information in the dataset ?\"</p> <p>(f) A Feature <code>f</code> is Deleted if and only if the Features F-Measure (c) <code>FM[f][c]</code> is always lower than the F-Measure Overall Average (d) for each class <code>c</code>. It answers the question: \"What are the features which do not contain more information than the mean of information in the dataset ?\"</p> </li> <li> <p>Compute the Features Contrast and Features Activation (based on F-Measure Marginal Averages comparison).</p> <p>(g) The F-Measure Marginal Averages for a given feature <code>f</code> is the average of Features F-Measure (c) for all classes <code>c</code> and for the given feature <code>f</code>. It answers the question: \"What are the mean of information contained by the feature <code>f</code> in all classes ?\"</p> <p>(h) The Features Contrast <code>FC[f][c]</code> for a given class <code>c</code> and a given selected feature <code>f</code> is the ratio between the Features F-Measure (c) <code>FM[f][c]</code> and the F-Measure Marginal Averages (g) for selected feature f put to the power of an Amplification Factor. It answers the question: \"How relevant is the feature <code>f</code> to distinguish the class <code>c</code> ?\"</p> <p>(i) A selected Feature <code>f</code> is Active for a given class <code>c</code> if and only if the Features Contrast (h) <code>FC[f][c]</code> is bigger than <code>1.0</code>. It answers the question : \"For which classes a selected feature <code>f</code> is relevant ?\"</p> </li> </ol> <p>In order to evaluate it according to a reference, a FMC modelization is represented by the Features Activation of its vector features, and a similarity score to the reference is computed, based on common metrics on clustering (homogeneity, completeness, v_measure).</p> <p>Attributes:</p> Name Type Description <code>data_vectors</code> <code>csr_matrix</code> <p>The sparse matrix representing the vector of each data (i.e. <code>data_vectors[d,f]</code> is the weight of data <code>d</code> for feature <code>f</code>).</p> <code>data_classes</code> <code>List[str]</code> <p>The list representing the class of each data (i.e. <code>data_classes[d]</code> is the class of data <code>d</code>).</p> <code>list_of_possible_features</code> <code>List[str]</code> <p>The list of existing vectors features.</p> <code>list_of_possible_classes</code> <code>List[str]</code> <p>The list of existing data classes.</p> <code>amplification_factor</code> <code>int</code> <p>The positive integer called \"amplification factor\" aimed at emphasize the feature contrast. Usually at <code>1</code>.</p> <code>features_frecall</code> <code>Dict[str, Dict[str, float]]</code> <p>The computation of Features Recall (Can the feature <code>f</code> distinguish the class <code>c</code> from other classes <code>l'</code> ?).</p> <code>features_fpredominance</code> <code>Dict[str, Dict[str, float]]</code> <p>The computation of Features Predominance (Can the feature <code>f</code> better identify the class <code>c</code> than the other features <code>f'</code> ?).</p> <code>features_fmeasure</code> <code>Dict[str, Dict[str, float]]</code> <p>The computation of Features F-Measure (How much information does the feature <code>f</code> contain about the class <code>c</code> ?).</p> <code>features_overall_average</code> <code>float</code> <p>The computation of Overall Average of Features F-Measure (What are the mean of information contained by features in all classes ?).</p> <code>features_selection</code> <code>Dict[str, bool]</code> <p>The computation of Features Selected (What are the features which contain more information than the mean of information in the dataset ?).</p> <code>features_marginal_averages</code> <code>Dict[str, float]</code> <p>The computation of Marginal Averages of Features F-Measure (What are the mean of information contained by the feature <code>f</code> in all classes ?).</p> <code>features_contrast</code> <code>Dict[str, Dict[str, float]]</code> <p>The computation of Features Contrast (How important is the feature <code>f</code> to distinguish the class <code>c</code> ?).</p> <code>features_activation</code> <code>Dict[str, Dict[str, bool]]</code> <p>The computation of Features Activation (For which classes a selected feature <code>f</code> is relevant ?).</p> Example <ul> <li>Basic usecase: \"What are the physical characteristics that most distinguish men from women ?\" <pre><code># Problem to solve.\nprint(\"&gt;&gt; What are the physical characteristics that most distinguish men from women ?\")\n\n###\n### Python dependencies.\n###\n\nfrom cognitivefactory.features_maximization_metric.fmc import FeaturesMaximizationMetric\nfrom scipy.sparse import csr_matrix\nfrom typing import List\n\n###\n### Data.\n###\n\n# Define people characteristics that will be studied.\ncharacteristics_studied: List[str] = [\n    \"Shoes size\",\n    \"Hair size\",\n    \"Nose size\",\n]\n\n# Get people characteristics.\npeople_characteristics: csr_matrix = csr_matrix(\n    [\n        [9, 5, 5],\n        [9, 10, 5],\n        [9, 20, 6],\n        [5, 15, 5],\n        [6, 25, 6],\n        [5, 25, 5],\n    ]\n)\n\n# Get people genders.\npeople_genders: List[str] = [\n    \"Man\",\n    \"Man\",\n    \"Man\",\n    \"Woman\",\n    \"Woman\",\n    \"Woman\",\n]\n\n###\n### Feature Maximization Metrics.\n###\n\n# Main computation.\nfmc_computer: FeaturesMaximizationMetric = FeaturesMaximizationMetric(\n    data_vectors=people_characteristics,\n    data_classes=people_genders,\n    list_of_possible_features=characteristics_studied,\n    amplification_factor=1,\n)\n\n###\n### Analysis 1: Delete characteristics that aren't relevant.\n###\n\nprint(\n    \"\\n\",\n    \"1. Which characteristic seems not relevant to distinguish men from women ?\",\n)\nfor characteristic in characteristics_studied:\n    if not fmc_computer.features_selection[characteristic]:\n        print(\n            \"    - '{0}' seems not relevant.\".format(characteristic)\n        )\n\n###\n### Analysis 2: Describe gender by relevant characteristics.\n###\n\nprint(\n    \"\\n\",\n    \"2. According to remaining characteristics:\",\n)\nfor gender in sorted(set(people_genders)):\n    print(\n        \"    - Which characteristic seems important to recognize a '{0}' ?\".format(gender)\n    )\n\n    for characteristic in fmc_computer.get_most_active_features_by_a_classe(\n        classe=gender,\n    ):\n        print(\n            \"        - '{0}' seems important (fmeasure of '{1:.2f}', contrast of '{2:.2f}').\".format(\n                characteristic,\n                fmc_computer.features_fmeasure[characteristic][gender],\n                fmc_computer.features_contrast[characteristic][gender],\n            )\n        )\n</code></pre></li> </ul> References <ul> <li>Features Maximization Metric: <code>Lamirel J.-C., Cuxac P., Hajlaoui K., A new approach for feature selection based on quality metric, Advances in Knowledge Discovery and Management, 6 (665), Springer.</code></li> </ul> Source code in <code>cognitivefactory\\features_maximization_metric\\fmc.py</code> <pre><code>class FeaturesMaximizationMetric:\nr\"\"\"\n    This class implements the ***Features Maximization Metric***.\n    It's a dataset modelization based on vectors features and data labels:\n    for each couple `(feature, classe)`, it gives a score (called **F-Measure**) that describe the power of identification and distinction of the feature for this classe.\n\n    This metric is computed by applying the following steps:\n\n        1. Compute the ***Features F-Measure*** metric (based on ***Features Recall*** and ***Features Predominance*** metrics).\n\n            &gt; (a) The ***Features Recall*** `FR[f][c]` for a given class `c` and a given feature `f` is the ratio between\n            &gt; the sum of the vectors weights of the feature `f` for data in class `c`\n            &gt; and the sum of all vectors weights of feature `f` for all data.\n            &gt; It answers the question: \"_Can the feature `f` distinguish the class `c` from other classes `c'` ?_\"\n\n            &gt; (b) The ***Features Predominance*** `FP[f][c]` for a given class `c` and a given feature `f` is the ratio between\n            &gt; the sum of the vectors weights of the feature `f` for data in class `c`\n            &gt; and the sum of all vectors weights of all feature `f'` for data in class `c`.\n            &gt; It answers the question: \"_Can the feature `f` better identify the class `c` than the other features `f'` ?_\"\n\n            &gt; (c) The ***Features F-Measure*** `FM[f][c]` for a given class `c` and a given feature `f` is\n            &gt; the harmonic mean of the ***Features Recall*** (a) and the ***Features Predominance*** (c).\n            &gt; It answers the question: \"_How much information does the feature `f` contain about the class `c` ?_\"\n\n        2. Compute the ***Features Selection*** (based on ***F-Measure Overall Average*** comparison).\n\n            &gt; (d) The ***F-Measure Overall Average*** is the average of ***Features F-Measure*** (c) for all classes `c` and for all features `f`.\n            &gt; It answers the question: \"_What are the mean of information contained by features in all classes ?_\"\n\n            &gt; (e) A feature `f` is ***Selected*** if and only if it exist at least one class `c` for which the ***Features F-Measure*** (c) `FM[f][c]` is bigger than the ***F-Measure Overall Average*** (d).\n            &gt; It answers the question: \"_What are the features which contain more information than the mean of information in the dataset ?_\"\n\n            &gt; (f) A Feature `f` is ***Deleted*** if and only if the ***Features F-Measure*** (c) `FM[f][c]` is always lower than the ***F-Measure Overall Average*** (d) for each class `c`.\n            &gt; It answers the question: \"_What are the features which do not contain more information than the mean of information in the dataset ?_\"\n\n        3. Compute the ***Features Contrast*** and ***Features Activation*** (based on ***F-Measure Marginal Averages*** comparison).\n\n            &gt; (g) The ***F-Measure Marginal Averages*** for a given feature `f` is the average of ***Features F-Measure*** (c) for all classes `c` and for the given feature `f`.\n            &gt; It answers the question: \"_What are the mean of information contained by the feature `f` in all classes ?_\"\n\n            &gt; (h) The ***Features Contrast*** `FC[f][c]` for a given class `c` and a given selected feature `f` is the ratio between\n            &gt; the ***Features F-Measure*** (c) `FM[f][c]`\n            &gt; and the ***F-Measure Marginal Averages*** (g) for selected feature f\n            &gt; put to the power of an ***Amplification Factor***.\n            &gt; It answers the question: \"_How relevant is the feature `f` to distinguish the class `c` ?_\"\n\n            &gt; (i) A selected Feature `f` is ***Active*** for a given class `c` if and only if the ***Features Contrast*** (h) `FC[f][c]` is bigger than `1.0`.\n            &gt; It answers the question : \"_For which classes a selected feature `f` is relevant ?_\"\n\n    In order to ***evaluate it according to a reference***, a FMC modelization is represented by the Features Activation of its vector features,\n    and a similarity score to the reference is computed, based on common metrics on clustering (homogeneity, completeness, v_measure).\n\n    Attributes:\n        data_vectors (csr_matrix): The sparse matrix representing the vector of each data (i.e. `data_vectors[d,f]` is the weight of data `d` for feature `f`).\n        data_classes (List[str]): The list representing the class of each data (i.e. `data_classes[d]` is the class of data `d`).\n        list_of_possible_features (List[str]): The list of existing vectors features.\n        list_of_possible_classes (List[str]):  The list of existing data classes.\n        amplification_factor (int): The positive integer called \"amplification factor\" aimed at emphasize the feature contrast. Usually at `1`.\n        features_frecall (Dict[str, Dict[str, float]]): The computation of *Features Recall* (_Can the feature `f` distinguish the class `c` from other classes `l'` ?_).\n        features_fpredominance (Dict[str, Dict[str, float]]): The computation of *Features Predominance* (_Can the feature `f` better identify the class `c` than the other features `f'` ?_).\n        features_fmeasure (Dict[str, Dict[str, float]]): The computation of *Features F-Measure* (_How much information does the feature `f` contain about the class `c` ?_).\n        features_overall_average (float): The computation of *Overall Average of Features F-Measure* (_What are the mean of information contained by features in all classes ?_).\n        features_selection (Dict[str, bool]): The computation of *Features Selected* (_What are the features which contain more information than the mean of information in the dataset ?_).\n        features_marginal_averages (Dict[str, float]):  The computation of *Marginal Averages of Features F-Measure* (_What are the mean of information contained by the feature `f` in all classes ?_).\n        features_contrast (Dict[str, Dict[str, float]]): The computation of *Features Contrast* (_How important is the feature `f` to distinguish the class `c` ?_).\n        features_activation (Dict[str, Dict[str, bool]]): The computation of *Features Activation* (_For which classes a selected feature `f` is relevant ?_).\n\n    Example:\n        - Basic usecase: \"_What are the physical characteristics that most distinguish men from women ?_\"\n        ```python\n\n        # Problem to solve.\n        print(\"&gt;&gt; What are the physical characteristics that most distinguish men from women ?\")\n\n        ###\n        ### Python dependencies.\n        ###\n\n        from cognitivefactory.features_maximization_metric.fmc import FeaturesMaximizationMetric\n        from scipy.sparse import csr_matrix\n        from typing import List\n\n        ###\n        ### Data.\n        ###\n\n        # Define people characteristics that will be studied.\n        characteristics_studied: List[str] = [\n            \"Shoes size\",\n            \"Hair size\",\n            \"Nose size\",\n        ]\n\n        # Get people characteristics.\n        people_characteristics: csr_matrix = csr_matrix(\n            [\n                [9, 5, 5],\n                [9, 10, 5],\n                [9, 20, 6],\n                [5, 15, 5],\n                [6, 25, 6],\n                [5, 25, 5],\n            ]\n        )\n\n        # Get people genders.\n        people_genders: List[str] = [\n            \"Man\",\n            \"Man\",\n            \"Man\",\n            \"Woman\",\n            \"Woman\",\n            \"Woman\",\n        ]\n\n        ###\n        ### Feature Maximization Metrics.\n        ###\n\n        # Main computation.\n        fmc_computer: FeaturesMaximizationMetric = FeaturesMaximizationMetric(\n            data_vectors=people_characteristics,\n            data_classes=people_genders,\n            list_of_possible_features=characteristics_studied,\n            amplification_factor=1,\n        )\n\n        ###\n        ### Analysis 1: Delete characteristics that aren't relevant.\n        ###\n\n        print(\n            \"\\n\",\n            \"1. Which characteristic seems not relevant to distinguish men from women ?\",\n        )\n        for characteristic in characteristics_studied:\n            if not fmc_computer.features_selection[characteristic]:\n                print(\n                    \"    - '{0}' seems not relevant.\".format(characteristic)\n                )\n\n        ###\n        ### Analysis 2: Describe gender by relevant characteristics.\n        ###\n\n        print(\n            \"\\n\",\n            \"2. According to remaining characteristics:\",\n        )\n        for gender in sorted(set(people_genders)):\n            print(\n                \"    - Which characteristic seems important to recognize a '{0}' ?\".format(gender)\n            )\n\n            for characteristic in fmc_computer.get_most_active_features_by_a_classe(\n                classe=gender,\n            ):\n                print(\n                    \"        - '{0}' seems important (fmeasure of '{1:.2f}', contrast of '{2:.2f}').\".format(\n                        characteristic,\n                        fmc_computer.features_fmeasure[characteristic][gender],\n                        fmc_computer.features_contrast[characteristic][gender],\n                    )\n                )\n        ```\n\n    References:\n        - Features Maximization Metric: `Lamirel J.-C., Cuxac P., Hajlaoui K., A new approach for feature selection based on quality metric, Advances in Knowledge Discovery and Management, 6 (665), Springer.`\n    \"\"\"\n\n    # =========================================================================================\n    # INITIALIZATION\n    # =========================================================================================\n\n    def __init__(\n        self,\n        data_vectors: csr_matrix,\n        data_classes: List[str],\n        list_of_possible_features: List[str],\n        amplification_factor: int = 1,\n        verbose: bool = False,\n    ):\n\"\"\"\n        The constructor for `FeaturesMaximizationMetric` class.\n        It applies the several steps of ***Feature Maximization***:\n            1. Compute the ***Features F-Measure*** metric (based on ***Features Recall*** and ***Features Predominance*** metrics).\n            2. Compute the ***Features Selection*** (based on ***F-Measure Overall Average*** comparison).\n            3. Compute the ***Features Contrast*** and ***Features Activation*** (based on ***F-Measure Marginal Averages*** comparison).\n\n        Args:\n            data_vectors (scipy.sparse.csr_matrix): A sparse matrix representing the vector of each data (i.e. `data_vectors[d,f]` is the weight of data `d` for feature `f`).\n            data_classes (List[str]): A list representing the class of each data (i.e. `data_classes[d]` is the class of data `d`).\n            list_of_possible_features (List[str]): A list of existing vectors features.\n            amplification_factor (int, optional): A positive integer called \"amplification factor\" aimed at emphasize the feature contrast. Defaults to `1`.\n            verbose (bool): An option to display progress status of computations. Defaults to `False`.\n\n        Raises:\n            ValueError: if `data_vectors` and `data_classes` have inconsistent shapes.\n            ValueError: if `data_vectors` and `list_of_possible_features` have inconsistent shapes.\n            ValueError: if `amplification_factor` is not a positive integer.\n        \"\"\"\n\n        ###\n        ### Check parameters.\n        ###\n\n        # Display progress status if requested.\n        if verbose:\n            print(\"`FeaturesMaximizationMetric.__init__`\", \":\", \"Check parameters.\")\n\n        # Check data size.\n        if data_vectors.shape[0] != len(data_classes):\n            raise ValueError(\n                \"The vectors `data_vectors` and the list of classes `data_classes` have inconsistent shapes (currently: '{0}' vs '{1}').\".format(\n                    data_vectors.shape[0],\n                    len(data_classes),\n                )\n            )\n\n        # Check features size.\n        if data_vectors.shape[1] != len(list_of_possible_features):\n            raise ValueError(\n                \"The vectors `data_vectors` and the list of features `list_of_possible_features` have inconsistent shapes (currently: '{0}' vs '{1}').\".format(\n                    data_vectors.shape[1],\n                    len(list_of_possible_features),\n                )\n            )\n\n        # Check amplification factor.\n        if (not isinstance(amplification_factor, int)) or amplification_factor &lt; 1:\n            raise ValueError(\n                \"The amplification factor `amplification_factor` has to be a positive integer (currently: '{0}').\".format(\n                    amplification_factor,\n                )\n            )\n\n        ###\n        ### Store parameters.\n        ###\n\n        # Display progress status if requested.\n        if verbose:\n            print(\"`FeaturesMaximizationMetric.__init__`\", \":\", \"Store parameters.\")\n\n        # Store data information.\n        self.data_vectors: csr_matrix = data_vectors\n        self.data_classes: List[str] = data_classes\n        # Store features and classes lists.\n        self.list_of_possible_features: List[str] = list_of_possible_features\n        self.list_of_possible_classes: List[str] = sorted(set(data_classes))\n        # Store amplification factor.\n        self.amplification_factor: int = amplification_factor\n\n        ###\n        ### Compute Features Maximization Metric.\n        ###\n\n        # Display progress status if requested.\n        if verbose:\n            print(\"`FeaturesMaximizationMetric.__init__`\", \":\", \"Start computations.\")\n\n        # 1. Compute the *Features F-Measure* metric (based on *Features Recall* and *Features Predominance* metrics).\n\n        # Display progress status if requested.\n        if verbose:\n            print(\"`FeaturesMaximizationMetric.__init__`\", \":\", \"Compute Features F-Measure.\")\n\n        # Initialize variables.\n        self.features_frecall: Dict[str, Dict[str, float]]\n        self.features_fpredominance: Dict[str, Dict[str, float]]\n        self.features_fmeasure: Dict[str, Dict[str, float]]\n        # Compute variables.\n        self._compute_features_frecall_fpredominance_fmeasure()\n\n        # 2. Perform a *Features Selection* (based on *F-Measure Overall Average* comparison).\n\n        # Display progress status if requested.\n        if verbose:\n            print(\"`FeaturesMaximizationMetric.__init__`\", \":\", \"Compute Features Selection.\")\n\n        # Initialize variables.\n        self.features_overall_average: float\n        self.features_selection: Dict[str, bool]\n        # Compute variables.\n        self._compute_features_selection()\n\n        # 3. Compute the *Features Contrast* and *Features Activation* (based on *F-Measure Marginal Averages* comparison).\n\n        # Display progress status if requested.\n        if verbose:\n            print(\"`FeaturesMaximizationMetric.__init__`\", \":\", \"Compute Features Contrast.\")\n\n        # Initialize variables.\n        self.features_marginal_averages: Dict[str, float]\n        self.features_contrast: Dict[str, Dict[str, float]]\n        self.features_activation: Dict[str, Dict[str, bool]]\n        # Compute variables.\n        self._compute_features_contrast_and_activation()\n\n        # Display progress status if requested.\n        if verbose:\n            print(\"`FeaturesMaximizationMetric.__init__`\", \":\", \"Computations done.\")\n\n    # ==============================================================================\n    # COMPUTE FEATURES F-MEASURE\n    # ==============================================================================\n\n    def _compute_features_frecall_fpredominance_fmeasure(\n        self,\n    ) -&gt; None:\n\"\"\"\n        Compute:\n            (a) the ***Features Recall*** (cf. `self.features_frecall`),\n            (b) the ***Features Predominance*** (cf. `self.features_fpredominance`), and\n            (c) the ***Features F-Measure*** (cf. `self.features_fmeasure`).\n        \"\"\"\n\n        ###\n        ### Temporary computations.\n        ###\n\n        # Temporary variable used to store sums of all vectors weights for a given feature `f` and a given class `c`.\n        # Needed for both Features Recall and Features Predominance computations.\n        sum_by_feature_and_classe: Dict[str, Dict[str, float]] = {\n            feature: {classe: 0.0 for classe in self.list_of_possible_classes}\n            for feature in self.list_of_possible_features\n        }\n\n        # Temporary variable used to store sums of all vectors weights for a given feature `f` and all classes.\n        # Needed for Features Recall computation.\n        sum_by_features: Dict[str, float] = {feature: 0.0 for feature in self.list_of_possible_features}\n\n        # Temporary variable used to store sums of all vectors weights for all features and a given class `c`.\n        # Needed for Features Predominance computation.\n        sum_by_classe: Dict[str, float] = {classe: 0.0 for classe in self.list_of_possible_classes}\n\n        # Index used to get non zero elements in the sparse matrix weights.\n        indices_x, indices_y = self.data_vectors.nonzero()\n\n        # Browse non zero weights in vectors to compute all the needed sums.\n        for index in range(self.data_vectors.nnz):\n            # Get needed information (data, class/ classe, feature, vectors weight)\n            data_index: int = indices_x[index]\n            data_classe: str = self.data_classes[data_index]\n            feature_index: int = indices_y[index]\n            data_feature: str = self.list_of_possible_features[feature_index]\n            weight: float = self.data_vectors[data_index, feature_index]  # TODO: check if np.nan ?\n\n            # Update the several sums.\n            sum_by_feature_and_classe[data_feature][data_classe] += weight\n            sum_by_features[data_feature] += weight\n            sum_by_classe[data_classe] += weight\n\n        ###\n        ### Features F-Measure computation.\n        ###\n\n        # Compute Features Recall.\n        self.features_frecall = {\n            feature: {\n                classe: (\n                    0.0  # TODO: set to np.nan ?\n                    if sum_by_features[feature] == 0\n                    else sum_by_feature_and_classe[feature][classe] / sum_by_features[feature]\n                )\n                for classe in self.list_of_possible_classes\n            }\n            for feature in self.list_of_possible_features\n        }\n\n        # Compute Features Predominance.\n        self.features_fpredominance = {\n            feature: {\n                classe: (\n                    0.0  # TODO: set to np.nan ?\n                    if sum_by_classe[classe] == 0\n                    else sum_by_feature_and_classe[feature][classe] / sum_by_classe[classe]\n                )\n                for classe in self.list_of_possible_classes\n            }\n            for feature in self.list_of_possible_features\n        }\n\n        # Compute Features F-Measure.\n        self.features_fmeasure = {\n            feature: {\n                classe: (\n                    0.0  # TODO: set to np.nan ?\n                    if (self.features_frecall[feature][classe] + self.features_fpredominance[feature][classe] == 0)\n                    else (\n                        2\n                        * (self.features_frecall[feature][classe] * self.features_fpredominance[feature][classe])\n                        / (self.features_frecall[feature][classe] + self.features_fpredominance[feature][classe])\n                    )\n                )\n                for classe in self.list_of_possible_classes\n            }\n            for feature in self.list_of_possible_features\n        }\n\n    # =============================================================================================\n    # COMPUTE FEATURES SELECTION\n    # =============================================================================================\n\n    def _compute_features_selection(\n        self,\n    ) -&gt; None:\n\"\"\"\n        Compute:\n            (d) the ***F-Measure Overall Average*** (cf. `self.features_overall_average`), and\n            (e) the ***Features Selected*** (cf. `self.features_selection`).\n        \"\"\"\n\n        ###\n        ### Features F-Measure Overall Average computation.\n        ###\n\n        # Temporary variable used to store the overall sum in order to compute the overall average of Features F-Measure.\n        overall_sum: float = 0.0\n        nb_overall: int = 0\n\n        # For each feature...\n        for feature1 in self.list_of_possible_features:\n            # For each classe...\n            for classe1 in self.list_of_possible_classes:\n                # Update the overall sum and count.\n                overall_sum += self.features_fmeasure[feature1][classe1]\n                nb_overall += 1\n\n        # Compute the overall average of Features F-Measure.\n        self.features_overall_average = 0.0 if nb_overall == 0 else overall_sum / nb_overall  # TODO: set to np.nan ?\n\n        ###\n        ### Features Selection computation.\n        ###\n\n        # Temporary variable used store the selected features.\n        self.features_selection = {}\n\n        # Browse features to determine the selected ones.\n        for feature2 in self.list_of_possible_features:\n            # Set default state of selection.\n            self.features_selection[feature2] = False\n\n            # For each feature, browse class to find one for which the Features F-Measure is bigger than the overall average.\n            for classe2 in self.list_of_possible_classes:\n                # Check that the Feature F-Measure is bigger than the overall average.\n                if self.features_fmeasure[feature2][classe2] &gt; self.features_overall_average:\n                    # Approve the selection and then break the loop.\n                    self.features_selection[feature2] = True\n                    break\n\n    # =============================================================================================\n    # COMPUTE FEATURES CONSTRAST AND ACTIVATION\n    # =============================================================================================\n\n    def _compute_features_contrast_and_activation(\n        self,\n    ) -&gt; None:\n\"\"\"\n        Compute:\n            (g) The ***F-Measure Marginal Averages*** (cf. `self.features_marginal_averages`), and\n            (h) The ***Features Contrast*** (cf. `self.features_contrast`).\n            (i) the ***Features Activation*** (cf. `self.features_activation`).\n        \"\"\"\n\n        ###\n        ### Features F-Measure Marginal computation.\n        ###\n\n        # Initialize the marginal average of Features F-Measure.\n        self.features_marginal_averages = {}\n\n        # Browse features to compute the averages.\n        for feature1 in self.list_of_possible_features:\n            # Temporary variable used to store the marginal sum in order to compute the marginal average of Features F-Measure over the current feature.\n            sum_marginal: float = 0.0\n            nb_marginal: int = 0\n\n            # Update the marginal sum of Features F-Measure over the current feature.\n            for classe1 in self.list_of_possible_classes:\n                sum_marginal += self.features_fmeasure[feature1][classe1]\n                nb_marginal += 1\n\n            # Compute the marginal averages of Features F-Measure over the current feature.\n            self.features_marginal_averages[feature1] = (\n                0.0 if nb_marginal == 0 else sum_marginal / nb_marginal\n            )  # TODO: set to np.nan ?\n\n        ###\n        ### Features Contrast computation.\n        ###\n\n        # Temporary variable used to store the contrast of a feature for a class.\n        self.features_contrast = {\n            feature2: {\n                classe2: (\n                    0.0  # TODO: set to np.nan ?\n                    if (self.features_selection[feature2] is False or self.features_marginal_averages[feature2] == 0)\n                    else (self.features_fmeasure[feature2][classe2] / self.features_marginal_averages[feature2])\n                    ** self.amplification_factor\n                )\n                for classe2 in self.list_of_possible_classes\n            }\n            for feature2 in self.list_of_possible_features\n        }\n\n        ###\n        ### Features Activation computation.\n        ###\n\n        # Temporary variable used store the features activation.\n        self.features_activation = {\n            feature3: {\n                classe3: bool(\n                    self.features_selection[feature3] is True and self.features_contrast[feature3][classe3] &gt; 1\n                )\n                for classe3 in self.list_of_possible_classes\n            }\n            for feature3 in self.list_of_possible_features\n        }\n\n    # =============================================================================================\n    # GET: MOST ACTIVATED CLASSES FOR A FEATURE\n    # =============================================================================================\n\n    def get_most_activated_classes_by_a_feature(\n        self,\n        feature: str,\n        activation_only: bool = True,\n        sort_by: Literal[\"contrast\", \"fmeasure\"] = \"contrast\",\n        max_number: Optional[int] = None,\n    ) -&gt; List[str]:\n\"\"\"\n        Get the list of classes for which the requested feature is the most relevant.\n\n        Args:\n            feature (str): The feature to analyze.\n            sort_by (Literal[\"contrast\", \"fmeasure\"]): The sort criterion for the list of classes. Defaults to `\"contrast\"`.\n            activation_only (bool): The option to get only activated classes. Defaults to `True`.\n            max_number (Optional[int]): The maximum number of classes to return. Defaults to `None`.\n\n        Raises:\n            ValueError: if `feature` is not in `self.list_of_possible_features`.\n            ValueError: if `sort_by` is not in `{\"contrast\", \"fmeasure\"}`.\n\n        Returns:\n            List[str]: The list of classes for which the requested feature is the most relevant.\n        \"\"\"\n\n        ###\n        ### Check parameters.\n        ###\n\n        # Check parameter `feature`.\n        if feature not in self.list_of_possible_features:\n            raise ValueError(\n                \"The requested feature `'{0}'` is unknown.\".format(\n                    feature,\n                )\n            )\n\n        # Check parameter `sort_by`.\n        if sort_by not in {\"contrast\", \"fmeasure\"}:\n            raise ValueError(\n                \"The sort option factor `sort_by` has to be in the following values: `{{'contrast', 'fmeasure'}}` (currently: '{0}').\".format(\n                    sort_by,\n                )\n            )\n\n        ###\n        ### Compute the requested list.\n        ###\n\n        # Define list of possible results (classe + contrast/fmeasure).\n        list_of_possible_results: List[Tuple[float, str]] = [\n            (\n                # 0: the metric: contrast or fmeasure.\n                (\n                    self.features_contrast[feature][classe]\n                    if sort_by == \"contrast\"\n                    else self.features_fmeasure[feature][classe]\n                ),\n                # 1: the classe.\n                classe,\n            )\n            for classe in self.list_of_possible_classes\n            if (activation_only is False or self.features_activation[feature][classe] is True)\n        ]\n\n        # Return top classes sorted by requested metric.\n        return [\n            activated_classe\n            for _, activated_classe in sorted(\n                list_of_possible_results,\n                reverse=True,\n            )\n        ][:max_number]\n\n    # =============================================================================================\n    # GET: MOST ACTIVATED FEATURES FOR A CLASSE\n    # =============================================================================================\n\n    def get_most_active_features_by_a_classe(\n        self,\n        classe: str,\n        activation_only: bool = True,\n        sort_by: Literal[\"contrast\", \"fmeasure\"] = \"contrast\",\n        max_number: Optional[int] = None,\n    ) -&gt; List[str]:\n\"\"\"\n        Get the list of features which are the most relevant for the requested classe.\n\n        Args:\n            classe (str): The classe to analyze.\n            sort_by (Literal[\"contrast\", \"fmeasure\"]): The sort criterion for the list of features. Defaults to `\"contrast\"`.\n            activation_only (bool): The option to get only active features. Defaults to `True`.\n            max_number (Optional[int]): The maximum number of features to return. Defaults to `None`.\n\n        Raises:\n            ValueError: if `classe` is not in `self.list_of_possible_classes`.\n            ValueError: if `sort_by` is not in `{\"contrast\", \"fmeasure\"}`.\n\n        Returns:\n            List[str]: The list of features which are the most relevant for the requested classe.\n        \"\"\"\n\n        ###\n        ### Check parameters.\n        ###\n\n        # Check parameter `feature`.\n        if classe not in self.list_of_possible_classes:\n            raise ValueError(\n                \"The requested classe `'{0}'` is unknown.\".format(\n                    classe,\n                )\n            )\n\n        # Check parameter `sort_by`.\n        if sort_by not in {\"contrast\", \"fmeasure\"}:\n            raise ValueError(\n                \"The sort option factor `sort_by` has to be in the following values: `{{'contrast', 'fmeasure'}}` (currently: '{0}').\".format(\n                    sort_by,\n                )\n            )\n\n        ###\n        ### Compute the requested list.\n        ###\n\n        # Define list of possible results (feature + contrast/fmeasure).\n        list_of_possible_results: List[Tuple[float, str]] = [\n            (\n                # 0: the metric: contrast or fmeasure.\n                (\n                    self.features_contrast[feature][classe]\n                    if sort_by == \"contrast\"\n                    else self.features_fmeasure[feature][classe]\n                ),\n                # 1: the feature.\n                feature,\n            )\n            for feature in self.list_of_possible_features\n            if (activation_only is False or self.features_activation[feature][classe] is True)\n        ]\n\n        # Return top features sorted by requested metric.\n        return [\n            active_feature\n            for _, active_feature in sorted(\n                list_of_possible_results,\n                reverse=True,\n            )\n        ][:max_number]\n\n    # =============================================================================================\n    # COMPARE: WITH AN OTHER FMC\n    # =============================================================================================\n\n    def compare(\n        self,\n        fmc_reference: \"FeaturesMaximizationMetric\",\n        rounded: Optional[int] = None,\n    ) -&gt; Tuple[float, float, float]:\n\"\"\"\n        Gives a similarity score in agreement with a reference FMC modelization.\n        The similarity score computation is based on common metrics on clustering (homogeneity, completeness, v_measure),\n        where each FMC modelization is represented by the Features Activation of their vector features.\n        In order to be able to compute these similarity, data classes can be different, but vector features must be the same in both FMC modelization.\n\n\n        Args:\n            fmc_reference (FeaturesMaximizationMetric): Another Features Maximization modelization used as reference for the comparison.\n            rounded (Optional[int]): The option to round the result to counter log approximation. Defaults to `None`.\n\n        Raises:\n            ValueError: if `list_of_possible_features` are different.\n\n        Returns:\n            Tuple[float, float, float]: Computation\n        \"\"\"\n\n        ###\n        ### Check parameters.\n        ###\n\n        # Check list_of_possible_features equality.\n        if self.list_of_possible_features != fmc_reference.list_of_possible_features:\n            list_of_in_excess_features: List[str] = [\n                feature\n                for feature in self.list_of_possible_features\n                if feature not in fmc_reference.list_of_possible_features\n            ]\n            list_of_missing_features: List[str] = [\n                feature\n                for feature in fmc_reference.list_of_possible_features\n                if feature not in self.list_of_possible_features\n            ]\n            raise ValueError(\n                \"The list of features `list_of_possible_features` must be the same for both FMC modelization. +: {0}, -: {1}\".format(\n                    str(list_of_in_excess_features), str(list_of_missing_features)\n                )\n            )\n\n        ###\n        ### Format Features Activation as classification label of features.\n        ###\n\n        # Initialize\n        list_of_self_features_activations: List[str] = []\n        list_of_reference_features_activations: List[str] = []\n\n        # Define default value if feature not activated.\n        # NB: we can't set a fixed value in case this value is in the list of possible classes...\n        # Example: can't set `\"\"` or `\"None\"` in case self.list_of_possible_classes==[\"A\", \"\"] and fmc_reference.list_of_possible_classes==[\"B\", \"None\"].\n        default_label_if_feature_not_activated: str = \"NOT_ACTIVATED:{possible_classe}\".format(\n            possible_classe=self.list_of_possible_classes + fmc_reference.list_of_possible_classes\n        )\n\n        # Browse activated features to\u00e0 compare Features Activation.\n        for feature in fmc_reference.list_of_possible_features:\n            # Get Features Activation.\n            list_of_most_activated_classes_for_feature_in_self: List[\n                str\n            ] = self.get_most_activated_classes_by_a_feature(\n                feature=feature,\n            )\n            list_of_most_activated_classes_for_feature_in_reference: List[\n                str\n            ] = fmc_reference.get_most_activated_classes_by_a_feature(\n                feature=feature,\n            )\n\n            # TODO: Skip if feature is not activated in both modelization.\n            if (\n                len(list_of_most_activated_classes_for_feature_in_self) != 1\n                and len(list_of_most_activated_classes_for_feature_in_reference) != 1\n            ):\n                continue\n\n            # Format Feature Activation as classification label. Set to `-1` if not activated.\n            list_of_self_features_activations.append(\n                list_of_most_activated_classes_for_feature_in_self[0]\n                if len(list_of_most_activated_classes_for_feature_in_self) == 1\n                else default_label_if_feature_not_activated\n            )\n            list_of_reference_features_activations.append(\n                list_of_most_activated_classes_for_feature_in_reference[0]\n                if len(list_of_most_activated_classes_for_feature_in_reference) == 1\n                else default_label_if_feature_not_activated\n            )\n\n        ###\n        ### Compute FMC modelizations similarity.\n        ###\n\n        # Compute standard metrics for clustering.\n        homogeneity: float\n        completeness: float\n        v_measure: float\n        homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(\n            labels_pred=list_of_self_features_activations,\n            labels_true=list_of_reference_features_activations,\n        )\n\n        # Round the results.\n        if rounded is not None:\n            homogeneity = round(homogeneity, rounded)\n            completeness = round(completeness, rounded)\n            v_measure = round(v_measure, rounded)\n\n        # Return values.\n        return homogeneity, completeness, v_measure\n</code></pre>"},{"location":"reference/cognitivefactory/features_maximization_metric/fmc/#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.__init__","title":"<code>__init__(data_vectors, data_classes, list_of_possible_features, amplification_factor=1, verbose=False)</code>","text":"<p>The constructor for <code>FeaturesMaximizationMetric</code> class. It applies the several steps of Feature Maximization:     1. Compute the Features F-Measure metric (based on Features Recall and Features Predominance metrics).     2. Compute the Features Selection (based on F-Measure Overall Average comparison).     3. Compute the Features Contrast and Features Activation (based on F-Measure Marginal Averages comparison).</p> <p>Parameters:</p> Name Type Description Default <code>data_vectors</code> <code>scipy.sparse.csr_matrix</code> <p>A sparse matrix representing the vector of each data (i.e. <code>data_vectors[d,f]</code> is the weight of data <code>d</code> for feature <code>f</code>).</p> required <code>data_classes</code> <code>List[str]</code> <p>A list representing the class of each data (i.e. <code>data_classes[d]</code> is the class of data <code>d</code>).</p> required <code>list_of_possible_features</code> <code>List[str]</code> <p>A list of existing vectors features.</p> required <code>amplification_factor</code> <code>int</code> <p>A positive integer called \"amplification factor\" aimed at emphasize the feature contrast. Defaults to <code>1</code>.</p> <code>1</code> <code>verbose</code> <code>bool</code> <p>An option to display progress status of computations. Defaults to <code>False</code>.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>data_vectors</code> and <code>data_classes</code> have inconsistent shapes.</p> <code>ValueError</code> <p>if <code>data_vectors</code> and <code>list_of_possible_features</code> have inconsistent shapes.</p> <code>ValueError</code> <p>if <code>amplification_factor</code> is not a positive integer.</p> Source code in <code>cognitivefactory\\features_maximization_metric\\fmc.py</code> <pre><code>def __init__(\n    self,\n    data_vectors: csr_matrix,\n    data_classes: List[str],\n    list_of_possible_features: List[str],\n    amplification_factor: int = 1,\n    verbose: bool = False,\n):\n\"\"\"\n    The constructor for `FeaturesMaximizationMetric` class.\n    It applies the several steps of ***Feature Maximization***:\n        1. Compute the ***Features F-Measure*** metric (based on ***Features Recall*** and ***Features Predominance*** metrics).\n        2. Compute the ***Features Selection*** (based on ***F-Measure Overall Average*** comparison).\n        3. Compute the ***Features Contrast*** and ***Features Activation*** (based on ***F-Measure Marginal Averages*** comparison).\n\n    Args:\n        data_vectors (scipy.sparse.csr_matrix): A sparse matrix representing the vector of each data (i.e. `data_vectors[d,f]` is the weight of data `d` for feature `f`).\n        data_classes (List[str]): A list representing the class of each data (i.e. `data_classes[d]` is the class of data `d`).\n        list_of_possible_features (List[str]): A list of existing vectors features.\n        amplification_factor (int, optional): A positive integer called \"amplification factor\" aimed at emphasize the feature contrast. Defaults to `1`.\n        verbose (bool): An option to display progress status of computations. Defaults to `False`.\n\n    Raises:\n        ValueError: if `data_vectors` and `data_classes` have inconsistent shapes.\n        ValueError: if `data_vectors` and `list_of_possible_features` have inconsistent shapes.\n        ValueError: if `amplification_factor` is not a positive integer.\n    \"\"\"\n\n    ###\n    ### Check parameters.\n    ###\n\n    # Display progress status if requested.\n    if verbose:\n        print(\"`FeaturesMaximizationMetric.__init__`\", \":\", \"Check parameters.\")\n\n    # Check data size.\n    if data_vectors.shape[0] != len(data_classes):\n        raise ValueError(\n            \"The vectors `data_vectors` and the list of classes `data_classes` have inconsistent shapes (currently: '{0}' vs '{1}').\".format(\n                data_vectors.shape[0],\n                len(data_classes),\n            )\n        )\n\n    # Check features size.\n    if data_vectors.shape[1] != len(list_of_possible_features):\n        raise ValueError(\n            \"The vectors `data_vectors` and the list of features `list_of_possible_features` have inconsistent shapes (currently: '{0}' vs '{1}').\".format(\n                data_vectors.shape[1],\n                len(list_of_possible_features),\n            )\n        )\n\n    # Check amplification factor.\n    if (not isinstance(amplification_factor, int)) or amplification_factor &lt; 1:\n        raise ValueError(\n            \"The amplification factor `amplification_factor` has to be a positive integer (currently: '{0}').\".format(\n                amplification_factor,\n            )\n        )\n\n    ###\n    ### Store parameters.\n    ###\n\n    # Display progress status if requested.\n    if verbose:\n        print(\"`FeaturesMaximizationMetric.__init__`\", \":\", \"Store parameters.\")\n\n    # Store data information.\n    self.data_vectors: csr_matrix = data_vectors\n    self.data_classes: List[str] = data_classes\n    # Store features and classes lists.\n    self.list_of_possible_features: List[str] = list_of_possible_features\n    self.list_of_possible_classes: List[str] = sorted(set(data_classes))\n    # Store amplification factor.\n    self.amplification_factor: int = amplification_factor\n\n    ###\n    ### Compute Features Maximization Metric.\n    ###\n\n    # Display progress status if requested.\n    if verbose:\n        print(\"`FeaturesMaximizationMetric.__init__`\", \":\", \"Start computations.\")\n\n    # 1. Compute the *Features F-Measure* metric (based on *Features Recall* and *Features Predominance* metrics).\n\n    # Display progress status if requested.\n    if verbose:\n        print(\"`FeaturesMaximizationMetric.__init__`\", \":\", \"Compute Features F-Measure.\")\n\n    # Initialize variables.\n    self.features_frecall: Dict[str, Dict[str, float]]\n    self.features_fpredominance: Dict[str, Dict[str, float]]\n    self.features_fmeasure: Dict[str, Dict[str, float]]\n    # Compute variables.\n    self._compute_features_frecall_fpredominance_fmeasure()\n\n    # 2. Perform a *Features Selection* (based on *F-Measure Overall Average* comparison).\n\n    # Display progress status if requested.\n    if verbose:\n        print(\"`FeaturesMaximizationMetric.__init__`\", \":\", \"Compute Features Selection.\")\n\n    # Initialize variables.\n    self.features_overall_average: float\n    self.features_selection: Dict[str, bool]\n    # Compute variables.\n    self._compute_features_selection()\n\n    # 3. Compute the *Features Contrast* and *Features Activation* (based on *F-Measure Marginal Averages* comparison).\n\n    # Display progress status if requested.\n    if verbose:\n        print(\"`FeaturesMaximizationMetric.__init__`\", \":\", \"Compute Features Contrast.\")\n\n    # Initialize variables.\n    self.features_marginal_averages: Dict[str, float]\n    self.features_contrast: Dict[str, Dict[str, float]]\n    self.features_activation: Dict[str, Dict[str, bool]]\n    # Compute variables.\n    self._compute_features_contrast_and_activation()\n\n    # Display progress status if requested.\n    if verbose:\n        print(\"`FeaturesMaximizationMetric.__init__`\", \":\", \"Computations done.\")\n</code></pre>"},{"location":"reference/cognitivefactory/features_maximization_metric/fmc/#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.compare","title":"<code>compare(fmc_reference, rounded=None)</code>","text":"<p>Gives a similarity score in agreement with a reference FMC modelization. The similarity score computation is based on common metrics on clustering (homogeneity, completeness, v_measure), where each FMC modelization is represented by the Features Activation of their vector features. In order to be able to compute these similarity, data classes can be different, but vector features must be the same in both FMC modelization.</p> <p>Parameters:</p> Name Type Description Default <code>fmc_reference</code> <code>FeaturesMaximizationMetric</code> <p>Another Features Maximization modelization used as reference for the comparison.</p> required <code>rounded</code> <code>Optional[int]</code> <p>The option to round the result to counter log approximation. Defaults to <code>None</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>list_of_possible_features</code> are different.</p> <p>Returns:</p> Type Description <code>Tuple[float, float, float]</code> <p>Tuple[float, float, float]: Computation</p> Source code in <code>cognitivefactory\\features_maximization_metric\\fmc.py</code> <pre><code>def compare(\n    self,\n    fmc_reference: \"FeaturesMaximizationMetric\",\n    rounded: Optional[int] = None,\n) -&gt; Tuple[float, float, float]:\n\"\"\"\n    Gives a similarity score in agreement with a reference FMC modelization.\n    The similarity score computation is based on common metrics on clustering (homogeneity, completeness, v_measure),\n    where each FMC modelization is represented by the Features Activation of their vector features.\n    In order to be able to compute these similarity, data classes can be different, but vector features must be the same in both FMC modelization.\n\n\n    Args:\n        fmc_reference (FeaturesMaximizationMetric): Another Features Maximization modelization used as reference for the comparison.\n        rounded (Optional[int]): The option to round the result to counter log approximation. Defaults to `None`.\n\n    Raises:\n        ValueError: if `list_of_possible_features` are different.\n\n    Returns:\n        Tuple[float, float, float]: Computation\n    \"\"\"\n\n    ###\n    ### Check parameters.\n    ###\n\n    # Check list_of_possible_features equality.\n    if self.list_of_possible_features != fmc_reference.list_of_possible_features:\n        list_of_in_excess_features: List[str] = [\n            feature\n            for feature in self.list_of_possible_features\n            if feature not in fmc_reference.list_of_possible_features\n        ]\n        list_of_missing_features: List[str] = [\n            feature\n            for feature in fmc_reference.list_of_possible_features\n            if feature not in self.list_of_possible_features\n        ]\n        raise ValueError(\n            \"The list of features `list_of_possible_features` must be the same for both FMC modelization. +: {0}, -: {1}\".format(\n                str(list_of_in_excess_features), str(list_of_missing_features)\n            )\n        )\n\n    ###\n    ### Format Features Activation as classification label of features.\n    ###\n\n    # Initialize\n    list_of_self_features_activations: List[str] = []\n    list_of_reference_features_activations: List[str] = []\n\n    # Define default value if feature not activated.\n    # NB: we can't set a fixed value in case this value is in the list of possible classes...\n    # Example: can't set `\"\"` or `\"None\"` in case self.list_of_possible_classes==[\"A\", \"\"] and fmc_reference.list_of_possible_classes==[\"B\", \"None\"].\n    default_label_if_feature_not_activated: str = \"NOT_ACTIVATED:{possible_classe}\".format(\n        possible_classe=self.list_of_possible_classes + fmc_reference.list_of_possible_classes\n    )\n\n    # Browse activated features to\u00e0 compare Features Activation.\n    for feature in fmc_reference.list_of_possible_features:\n        # Get Features Activation.\n        list_of_most_activated_classes_for_feature_in_self: List[\n            str\n        ] = self.get_most_activated_classes_by_a_feature(\n            feature=feature,\n        )\n        list_of_most_activated_classes_for_feature_in_reference: List[\n            str\n        ] = fmc_reference.get_most_activated_classes_by_a_feature(\n            feature=feature,\n        )\n\n        # TODO: Skip if feature is not activated in both modelization.\n        if (\n            len(list_of_most_activated_classes_for_feature_in_self) != 1\n            and len(list_of_most_activated_classes_for_feature_in_reference) != 1\n        ):\n            continue\n\n        # Format Feature Activation as classification label. Set to `-1` if not activated.\n        list_of_self_features_activations.append(\n            list_of_most_activated_classes_for_feature_in_self[0]\n            if len(list_of_most_activated_classes_for_feature_in_self) == 1\n            else default_label_if_feature_not_activated\n        )\n        list_of_reference_features_activations.append(\n            list_of_most_activated_classes_for_feature_in_reference[0]\n            if len(list_of_most_activated_classes_for_feature_in_reference) == 1\n            else default_label_if_feature_not_activated\n        )\n\n    ###\n    ### Compute FMC modelizations similarity.\n    ###\n\n    # Compute standard metrics for clustering.\n    homogeneity: float\n    completeness: float\n    v_measure: float\n    homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(\n        labels_pred=list_of_self_features_activations,\n        labels_true=list_of_reference_features_activations,\n    )\n\n    # Round the results.\n    if rounded is not None:\n        homogeneity = round(homogeneity, rounded)\n        completeness = round(completeness, rounded)\n        v_measure = round(v_measure, rounded)\n\n    # Return values.\n    return homogeneity, completeness, v_measure\n</code></pre>"},{"location":"reference/cognitivefactory/features_maximization_metric/fmc/#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.get_most_activated_classes_by_a_feature","title":"<code>get_most_activated_classes_by_a_feature(feature, activation_only=True, sort_by='contrast', max_number=None)</code>","text":"<p>Get the list of classes for which the requested feature is the most relevant.</p> <p>Parameters:</p> Name Type Description Default <code>feature</code> <code>str</code> <p>The feature to analyze.</p> required <code>sort_by</code> <code>Literal['contrast', 'fmeasure']</code> <p>The sort criterion for the list of classes. Defaults to <code>\"contrast\"</code>.</p> <code>'contrast'</code> <code>activation_only</code> <code>bool</code> <p>The option to get only activated classes. Defaults to <code>True</code>.</p> <code>True</code> <code>max_number</code> <code>Optional[int]</code> <p>The maximum number of classes to return. Defaults to <code>None</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>feature</code> is not in <code>self.list_of_possible_features</code>.</p> <code>ValueError</code> <p>if <code>sort_by</code> is not in <code>{\"contrast\", \"fmeasure\"}</code>.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: The list of classes for which the requested feature is the most relevant.</p> Source code in <code>cognitivefactory\\features_maximization_metric\\fmc.py</code> <pre><code>def get_most_activated_classes_by_a_feature(\n    self,\n    feature: str,\n    activation_only: bool = True,\n    sort_by: Literal[\"contrast\", \"fmeasure\"] = \"contrast\",\n    max_number: Optional[int] = None,\n) -&gt; List[str]:\n\"\"\"\n    Get the list of classes for which the requested feature is the most relevant.\n\n    Args:\n        feature (str): The feature to analyze.\n        sort_by (Literal[\"contrast\", \"fmeasure\"]): The sort criterion for the list of classes. Defaults to `\"contrast\"`.\n        activation_only (bool): The option to get only activated classes. Defaults to `True`.\n        max_number (Optional[int]): The maximum number of classes to return. Defaults to `None`.\n\n    Raises:\n        ValueError: if `feature` is not in `self.list_of_possible_features`.\n        ValueError: if `sort_by` is not in `{\"contrast\", \"fmeasure\"}`.\n\n    Returns:\n        List[str]: The list of classes for which the requested feature is the most relevant.\n    \"\"\"\n\n    ###\n    ### Check parameters.\n    ###\n\n    # Check parameter `feature`.\n    if feature not in self.list_of_possible_features:\n        raise ValueError(\n            \"The requested feature `'{0}'` is unknown.\".format(\n                feature,\n            )\n        )\n\n    # Check parameter `sort_by`.\n    if sort_by not in {\"contrast\", \"fmeasure\"}:\n        raise ValueError(\n            \"The sort option factor `sort_by` has to be in the following values: `{{'contrast', 'fmeasure'}}` (currently: '{0}').\".format(\n                sort_by,\n            )\n        )\n\n    ###\n    ### Compute the requested list.\n    ###\n\n    # Define list of possible results (classe + contrast/fmeasure).\n    list_of_possible_results: List[Tuple[float, str]] = [\n        (\n            # 0: the metric: contrast or fmeasure.\n            (\n                self.features_contrast[feature][classe]\n                if sort_by == \"contrast\"\n                else self.features_fmeasure[feature][classe]\n            ),\n            # 1: the classe.\n            classe,\n        )\n        for classe in self.list_of_possible_classes\n        if (activation_only is False or self.features_activation[feature][classe] is True)\n    ]\n\n    # Return top classes sorted by requested metric.\n    return [\n        activated_classe\n        for _, activated_classe in sorted(\n            list_of_possible_results,\n            reverse=True,\n        )\n    ][:max_number]\n</code></pre>"},{"location":"reference/cognitivefactory/features_maximization_metric/fmc/#cognitivefactory.features_maximization_metric.fmc.FeaturesMaximizationMetric.get_most_active_features_by_a_classe","title":"<code>get_most_active_features_by_a_classe(classe, activation_only=True, sort_by='contrast', max_number=None)</code>","text":"<p>Get the list of features which are the most relevant for the requested classe.</p> <p>Parameters:</p> Name Type Description Default <code>classe</code> <code>str</code> <p>The classe to analyze.</p> required <code>sort_by</code> <code>Literal['contrast', 'fmeasure']</code> <p>The sort criterion for the list of features. Defaults to <code>\"contrast\"</code>.</p> <code>'contrast'</code> <code>activation_only</code> <code>bool</code> <p>The option to get only active features. Defaults to <code>True</code>.</p> <code>True</code> <code>max_number</code> <code>Optional[int]</code> <p>The maximum number of features to return. Defaults to <code>None</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>classe</code> is not in <code>self.list_of_possible_classes</code>.</p> <code>ValueError</code> <p>if <code>sort_by</code> is not in <code>{\"contrast\", \"fmeasure\"}</code>.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: The list of features which are the most relevant for the requested classe.</p> Source code in <code>cognitivefactory\\features_maximization_metric\\fmc.py</code> <pre><code>def get_most_active_features_by_a_classe(\n    self,\n    classe: str,\n    activation_only: bool = True,\n    sort_by: Literal[\"contrast\", \"fmeasure\"] = \"contrast\",\n    max_number: Optional[int] = None,\n) -&gt; List[str]:\n\"\"\"\n    Get the list of features which are the most relevant for the requested classe.\n\n    Args:\n        classe (str): The classe to analyze.\n        sort_by (Literal[\"contrast\", \"fmeasure\"]): The sort criterion for the list of features. Defaults to `\"contrast\"`.\n        activation_only (bool): The option to get only active features. Defaults to `True`.\n        max_number (Optional[int]): The maximum number of features to return. Defaults to `None`.\n\n    Raises:\n        ValueError: if `classe` is not in `self.list_of_possible_classes`.\n        ValueError: if `sort_by` is not in `{\"contrast\", \"fmeasure\"}`.\n\n    Returns:\n        List[str]: The list of features which are the most relevant for the requested classe.\n    \"\"\"\n\n    ###\n    ### Check parameters.\n    ###\n\n    # Check parameter `feature`.\n    if classe not in self.list_of_possible_classes:\n        raise ValueError(\n            \"The requested classe `'{0}'` is unknown.\".format(\n                classe,\n            )\n        )\n\n    # Check parameter `sort_by`.\n    if sort_by not in {\"contrast\", \"fmeasure\"}:\n        raise ValueError(\n            \"The sort option factor `sort_by` has to be in the following values: `{{'contrast', 'fmeasure'}}` (currently: '{0}').\".format(\n                sort_by,\n            )\n        )\n\n    ###\n    ### Compute the requested list.\n    ###\n\n    # Define list of possible results (feature + contrast/fmeasure).\n    list_of_possible_results: List[Tuple[float, str]] = [\n        (\n            # 0: the metric: contrast or fmeasure.\n            (\n                self.features_contrast[feature][classe]\n                if sort_by == \"contrast\"\n                else self.features_fmeasure[feature][classe]\n            ),\n            # 1: the feature.\n            feature,\n        )\n        for feature in self.list_of_possible_features\n        if (activation_only is False or self.features_activation[feature][classe] is True)\n    ]\n\n    # Return top features sorted by requested metric.\n    return [\n        active_feature\n        for _, active_feature in sorted(\n            list_of_possible_results,\n            reverse=True,\n        )\n    ][:max_number]\n</code></pre>"},{"location":"coverage/","title":"Coverage report","text":""}]}